{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:44:59.875459Z",
     "iopub.status.busy": "2024-12-10T06:44:59.874634Z",
     "iopub.status.idle": "2024-12-10T06:45:28.125023Z",
     "shell.execute_reply": "2024-12-10T06:45:28.123748Z",
     "shell.execute_reply.started": "2024-12-10T06:44:59.875387Z"
    },
    "trusted": true
   },
   "source": [
    "# Original notebook:\n",
    "https://www.kaggle.com/code/takanashihumbert/cibmtr-using-official-metric-in-tree-based-models/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:43.061047Z",
     "iopub.status.busy": "2024-12-10T06:45:43.060393Z",
     "iopub.status.idle": "2024-12-10T06:45:43.067555Z",
     "shell.execute_reply": "2024-12-10T06:45:43.066738Z",
     "shell.execute_reply.started": "2024-12-10T06:45:43.061012Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are using xgboost == 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, LabelEncoder\n",
    "import os, glob, math, gc, warnings, random, joblib\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool, CatBoostRegressor\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import xgboost as xgb\n",
    "print(\"we are using xgboost ==\", xgb.__version__)\n",
    "from lightgbm import LGBMRegressor, callback\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:48.24552Z",
     "iopub.status.busy": "2024-12-10T06:45:48.24517Z",
     "iopub.status.idle": "2024-12-10T06:45:48.25547Z",
     "shell.execute_reply": "2024-12-10T06:45:48.254582Z",
     "shell.execute_reply.started": "2024-12-10T06:45:48.245489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def custom_score(solution, submission, row_id_column_name, prediction_label='prediction', print_info=True):\n",
    "    \n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "    \n",
    "    event_label = 'efs'\n",
    "    interval_label = 'efs_time'\n",
    "    \n",
    "    for col in submission.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(submission[col]):\n",
    "            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n",
    "    # Merging solution and submission dfs on ID\n",
    "    merged_df = pd.concat([solution, submission], axis=1)\n",
    "    merged_df.reset_index(inplace=True)\n",
    "    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n",
    "    metric_dict = {}\n",
    "    for race in sorted(merged_df_race_dict.keys()):\n",
    "        # Retrieving values from y_test based on index\n",
    "        indices = sorted(merged_df_race_dict[race])\n",
    "        merged_df_race = merged_df.iloc[indices]\n",
    "        # Calculate the concordance index\n",
    "        c_index_race = concordance_index(\n",
    "                        merged_df_race[interval_label],\n",
    "                        -merged_df_race[prediction_label],\n",
    "                        merged_df_race[event_label])\n",
    "\n",
    "        metric_dict[race] = c_index_race\n",
    "\n",
    "    race_c_index = list(metric_dict.values())\n",
    "    c_score = float(np.mean(race_c_index) - np.std(race_c_index))\n",
    "    if print_info:\n",
    "        print(f\"{Fore.GREEN}{Style.BRIGHT}# c-index={c_score:.4f}, mean={np.mean(race_c_index):.4f} std={np.std(race_c_index):.4f}{Style.RESET_ALL}\")\n",
    "    \n",
    "    return c_score, metric_dict\n",
    "\n",
    "\n",
    "def display_overall(df):\n",
    "    \n",
    "    race_groups = [\n",
    "        'American Indian or Alaska Native', 'Asian',\n",
    "       'Black or African-American', 'More than one race',\n",
    "       'Native Hawaiian or other Pacific Islander', 'White'\n",
    "    ]\n",
    "    df['mean'] = df[race_groups].mean(axis=1)\n",
    "    df['std'] = np.std(df[race_groups], axis=1)\n",
    "    df['score'] = df['mean'] - df['std']\n",
    "    df = df.T\n",
    "    df['Overall'] = df.mean(axis=1)\n",
    "    temp = df.drop(index=['std']).values\n",
    "    display(df\n",
    "            .iloc[:len(race_groups)]\n",
    "            .style\n",
    "            .format(precision=4)\n",
    "            .background_gradient(axis=None, vmin=temp.min(), vmax=temp.max(), cmap=\"cool\")\n",
    "            .concat(df.iloc[len(race_groups):].style.format(precision=3))\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:48.958627Z",
     "iopub.status.busy": "2024-12-10T06:45:48.957939Z",
     "iopub.status.idle": "2024-12-10T06:45:49.287763Z",
     "shell.execute_reply": "2024-12-10T06:45:49.28684Z",
     "shell.execute_reply.started": "2024-12-10T06:45:48.95859Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (1057, 60)\n",
      "Balanced Test shape: (2880, 60)\n",
      "Train shape: (25920, 60)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"../preprocessed_data/custom_test_0.1_imbalanced.csv\")\n",
    "print(\"Test shape:\", test.shape )\n",
    "\n",
    "test_balanced = pd.read_csv(\"../preprocessed_data/custom_test_0.1_balanced.csv\")\n",
    "print(\"Balanced Test shape:\", test_balanced.shape )\n",
    "\n",
    "train = pd.read_csv(\"../preprocessed_data/custom_train_0.9_balanced.csv\")\n",
    "print(\"Train shape:\",train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:49.936711Z",
     "iopub.status.busy": "2024-12-10T06:45:49.935964Z",
     "iopub.status.idle": "2024-12-10T06:45:49.941283Z",
     "shell.execute_reply": "2024-12-10T06:45:49.940427Z",
     "shell.execute_reply.started": "2024-12-10T06:45:49.936677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def transform_survival_probability(df, time_col='efs_time', event_col='efs'):\n",
    "    \"\"\"\n",
    "    Transform using survival probability estimates\n",
    "    \"\"\"\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(df[time_col], df[event_col])\n",
    "    y = kmf.survival_function_at_times(df[time_col]).values\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's substract 0.1 instead of 0.2 from the Kaplan Meier survival scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:50.340453Z",
     "iopub.status.busy": "2024-12-10T06:45:50.340144Z",
     "iopub.status.idle": "2024-12-10T06:45:50.697919Z",
     "shell.execute_reply": "2024-12-10T06:45:50.69707Z",
     "shell.execute_reply.started": "2024-12-10T06:45:50.340393Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SUBTRACT_KP_SCORE = 0.15\n",
    "\n",
    "train[\"label\"] = transform_survival_probability(train, time_col='efs_time', event_col='efs')\n",
    "train.loc[train['efs']==0, 'label'] -= SUBTRACT_KP_SCORE # or -0.1 according to other notebook\n",
    "\n",
    "test['label'] = transform_survival_probability(test, time_col='efs_time', event_col='efs')\n",
    "test.loc[test['efs']==0, 'label'] -= SUBTRACT_KP_SCORE # or -0.1 according to other notebook\n",
    "test_balanced['label'] = transform_survival_probability(test_balanced, time_col='efs_time', event_col='efs')\n",
    "test_balanced.loc[test_balanced['efs']==0, 'label'] -= SUBTRACT_KP_SCORE # or -0.1 according to other notebook\n",
    "\n",
    "sns.histplot(data=train, x='label', hue='efs', element='step', common_norm=False)\n",
    "plt.legend(title='efs')\n",
    "plt.title('Distribution of Target by EFS')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's convert year_hct to year_hct_from_baseline to avoid a big difference in scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_YEAR = train['year_hct'].min() # 2008\n",
    "train['year_hct_relative'] = train['year_hct'] - MIN_YEAR\n",
    "train.drop(columns=['year_hct'], inplace=True)\n",
    "\n",
    "test['year_hct_relative'] = test['year_hct'] - MIN_YEAR\n",
    "test.drop(columns=['year_hct'], inplace=True)   \n",
    "\n",
    "test_balanced['year_hct_relative'] = test_balanced['year_hct'] - MIN_YEAR   \n",
    "test_balanced.drop(columns=['year_hct'], inplace=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:52.769417Z",
     "iopub.status.busy": "2024-12-10T06:45:52.769048Z",
     "iopub.status.idle": "2024-12-10T06:45:52.774899Z",
     "shell.execute_reply": "2024-12-10T06:45:52.773877Z",
     "shell.execute_reply.started": "2024-12-10T06:45:52.769363Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 FEATURES: ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'hla_match_c_high', 'hla_high_res_8', 'tbi_status', 'arrhythmia', 'hla_low_res_6', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'hla_high_res_6', 'cmv_status', 'hla_high_res_10', 'hla_match_dqb1_high', 'tce_imm_match', 'hla_nmdp_6', 'hla_match_c_low', 'rituximab', 'hla_match_drb1_low', 'hla_match_dqb1_low', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hla_match_a_high', 'hepatic_severe', 'donor_age', 'prior_tumor', 'hla_match_b_low', 'peptic_ulcer', 'age_at_hct', 'hla_match_a_low', 'gvhd_proph', 'rheum_issue', 'sex_match', 'hla_match_b_high', 'race_group', 'comorbidity_score', 'karnofsky_score', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'hla_low_res_8', 'cardiac', 'hla_match_drb1_high', 'pulm_moderate', 'hla_low_res_10', 'year_hct_relative']\n"
     ]
    }
   ],
   "source": [
    "RMV = [\"ID\",\"efs\",\"efs_time\",\"label\",'y','kfold']\n",
    "FEATURES = [c for c in train.columns if not c in RMV]\n",
    "print(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:53.095326Z",
     "iopub.status.busy": "2024-12-10T06:45:53.095056Z",
     "iopub.status.idle": "2024-12-10T06:45:53.863499Z",
     "shell.execute_reply": "2024-12-10T06:45:53.862823Z",
     "shell.execute_reply.started": "2024-12-10T06:45:53.095299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CAT_FEATURES = []\n",
    "for c in FEATURES:\n",
    "    if train[c].dtype==\"object\":\n",
    "        CAT_FEATURES.append(c)\n",
    "        train[c] = train[c].fillna(\"NAN\")\n",
    "        test[c] = test[c].fillna(\"NAN\")\n",
    "        test_balanced[c] = test_balanced[c].fillna(\"NAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:53.864972Z",
     "iopub.status.busy": "2024-12-10T06:45:53.864713Z",
     "iopub.status.idle": "2024-12-10T06:45:53.955581Z",
     "shell.execute_reply": "2024-12-10T06:45:53.954793Z",
     "shell.execute_reply.started": "2024-12-10T06:45:53.864946Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CATEGORICAL FEATURES: dri_score, psych_disturb, cyto_score, diabetes, tbi_status, arrhythmia, graft_type, vent_hist, renal_issue, pulm_severe, prim_disease_hct, cmv_status, tce_imm_match, rituximab, prod_type, cyto_score_detail, conditioning_intensity, ethnicity, obesity, mrd_hct, in_vivo_tcd, tce_match, hepatic_severe, prior_tumor, peptic_ulcer, gvhd_proph, rheum_issue, sex_match, race_group, hepatic_mild, tce_div_match, donor_related, melphalan_dose, cardiac, pulm_moderate, "
     ]
    }
   ],
   "source": [
    "combined = pd.concat([train, test, test_balanced], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"The CATEGORICAL FEATURES: \", end=\"\")\n",
    "for c in FEATURES:\n",
    "    if c in CAT_FEATURES:\n",
    "        print(f\"{c}, \", end=\"\")\n",
    "        combined[c] = combined[c].astype(\"category\")\n",
    "    else:\n",
    "        if combined[c].dtype == \"float64\":\n",
    "            combined[c] = combined[c].astype(\"float32\")\n",
    "        if combined[c].dtype == \"int64\":\n",
    "            combined[c] = combined[c].astype(\"int32\")\n",
    "\n",
    "train = combined.iloc[:len(train)].copy()\n",
    "test = combined.iloc[len(train):len(train) + len(test)].reset_index(drop=True).copy()\n",
    "test_balanced = combined.iloc[len(train) + len(test):].reset_index(drop=True).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:55.924938Z",
     "iopub.status.busy": "2024-12-10T06:45:55.924108Z",
     "iopub.status.idle": "2024-12-10T06:45:55.975816Z",
     "shell.execute_reply": "2024-12-10T06:45:55.975216Z",
     "shell.execute_reply.started": "2024-12-10T06:45:55.924902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "folds = 5\n",
    "train['kfold'] = -1  \n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "groups = train['efs'].astype(str)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X=train, y=groups)):\n",
    "    train.loc[val_idx, 'kfold'] = fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:57.061938Z",
     "iopub.status.busy": "2024-12-10T06:45:57.061563Z",
     "iopub.status.idle": "2024-12-10T06:45:57.067525Z",
     "shell.execute_reply": "2024-12-10T06:45:57.0666Z",
     "shell.execute_reply.started": "2024-12-10T06:45:57.061902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def CIndexMetric_XGB(y_true, y_pred):\n",
    "    ds_pred[\"prediction\"] = y_pred\n",
    "    cindex_score, _ = custom_score(ds_true.copy(), ds_pred.copy(), \"ID\", print_info=False)\n",
    "    return -cindex_score\n",
    "\n",
    "def CIndexMetric_LGB(y_true, y_pred):\n",
    "    ds_pred[\"prediction\"] = y_pred\n",
    "    cindex_score, _ = custom_score(ds_true.copy(), ds_pred.copy(), \"ID\", print_info=False)\n",
    "    return ('C-Index', cindex_score, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek's adversarial training for group invariance and group DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Adversarial+DRO Iteration 1/3 ===\n",
      "\n",
      "Fold 1/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.58985\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.66670\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.67257\n",
      "[1300]\tvalidation_0-CIndexMetric_XGB:-0.67365\n",
      "\u001b[32m\u001b[1m# c-index=0.6739, mean=0.6876 std=0.0137\u001b[0m\n",
      "\n",
      "Fold 2/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.59093\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.66839\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.67378\n",
      "[1500]\tvalidation_0-CIndexMetric_XGB:-0.67550\n",
      "[1563]\tvalidation_0-CIndexMetric_XGB:-0.67550\n",
      "\u001b[32m\u001b[1m# c-index=0.6758, mean=0.6910 std=0.0152\u001b[0m\n",
      "\n",
      "Fold 3/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.59818\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.67551\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.67875\n",
      "[1387]\tvalidation_0-CIndexMetric_XGB:-0.67932\n",
      "\u001b[32m\u001b[1m# c-index=0.6795, mean=0.6855 std=0.0060\u001b[0m\n",
      "\n",
      "Fold 4/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.59214\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.66485\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.66996\n",
      "[1387]\tvalidation_0-CIndexMetric_XGB:-0.67055\n",
      "\u001b[32m\u001b[1m# c-index=0.6711, mean=0.6832 std=0.0122\u001b[0m\n",
      "\n",
      "Fold 5/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.59675\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.67091\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.67518\n",
      "[1476]\tvalidation_0-CIndexMetric_XGB:-0.67621\n",
      "\u001b[32m\u001b[1m# c-index=0.6765, mean=0.6870 std=0.0106\u001b[0m\n",
      "\n",
      "=== Adversarial+DRO Iteration 2/3 ===\n",
      "\n",
      "Fold 1/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.58985\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.66700\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.67320\n",
      "[1467]\tvalidation_0-CIndexMetric_XGB:-0.67416\n",
      "\u001b[32m\u001b[1m# c-index=0.6743, mean=0.6875 std=0.0132\u001b[0m\n",
      "\n",
      "Fold 2/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.59093\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.66868\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.67383\n",
      "[1491]\tvalidation_0-CIndexMetric_XGB:-0.67532\n",
      "\u001b[32m\u001b[1m# c-index=0.6755, mean=0.6905 std=0.0151\u001b[0m\n",
      "\n",
      "Fold 3/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.59818\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.67531\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.67892\n",
      "[1165]\tvalidation_0-CIndexMetric_XGB:-0.67901\n",
      "\u001b[32m\u001b[1m# c-index=0.6794, mean=0.6856 std=0.0062\u001b[0m\n",
      "\n",
      "Fold 4/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.59214\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.66405\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.66891\n",
      "[1445]\tvalidation_0-CIndexMetric_XGB:-0.67009\n",
      "\u001b[32m\u001b[1m# c-index=0.6705, mean=0.6821 std=0.0116\u001b[0m\n",
      "\n",
      "Fold 5/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.59675\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.67085\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.67450\n",
      "[1476]\tvalidation_0-CIndexMetric_XGB:-0.67592\n",
      "\u001b[32m\u001b[1m# c-index=0.6762, mean=0.6870 std=0.0108\u001b[0m\n",
      "\n",
      "=== Adversarial+DRO Iteration 3/3 ===\n",
      "\n",
      "Fold 1/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.58985\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.66709\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.67308\n",
      "[1500]\tvalidation_0-CIndexMetric_XGB:-0.67455\n",
      "[1542]\tvalidation_0-CIndexMetric_XGB:-0.67473\n",
      "\u001b[32m\u001b[1m# c-index=0.6748, mean=0.6879 std=0.0132\u001b[0m\n",
      "\n",
      "Fold 2/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.59093\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.66871\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.67426\n",
      "[1436]\tvalidation_0-CIndexMetric_XGB:-0.67555\n",
      "\u001b[32m\u001b[1m# c-index=0.6758, mean=0.6906 std=0.0148\u001b[0m\n",
      "\n",
      "Fold 3/5\n",
      "[0]\tvalidation_0-CIndexMetric_XGB:-0.59818\n",
      "[500]\tvalidation_0-CIndexMetric_XGB:-0.67521\n",
      "[1000]\tvalidation_0-CIndexMetric_XGB:-0.67856\n",
      "[1021]\tvalidation_0-CIndexMetric_XGB:-0.67860\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[18:24:14] /Users/runner/work/xgboost/xgboost/src/gbm/gbtree.h:123: Check failed: end <= model.BoostedRounds() (1100 vs. 1023) : Out of range for tree layers.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000013f7f8428 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x000000013f9ceb3c xgboost::gbm::detail::LayerToTree(xgboost::gbm::GBTreeModel const&, int, int) + 340\n  [bt] (2) 3   libxgboost.dylib                    0x000000013f9c7234 xgboost::gbm::GBTree::PredictLeaf(xgboost::DMatrix*, xgboost::HostDeviceVector<float>*, unsigned int, unsigned int) + 56\n  [bt] (3) 4   libxgboost.dylib                    0x000000013f9e4810 xgboost::LearnerImpl::Predict(std::__1::shared_ptr<xgboost::DMatrix>, bool, xgboost::HostDeviceVector<float>*, int, int, bool, bool, bool, bool, bool) + 460\n  [bt] (4) 5   libxgboost.dylib                    0x000000013f879058 XGBoosterPredictFromDMatrix + 864\n  [bt] (5) 6   libffi.8.dylib                      0x0000000103b0c04c ffi_call_SYSV + 76\n  [bt] (6) 7   libffi.8.dylib                      0x0000000103b09834 ffi_call_int + 1404\n  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000103ae40ac _ctypes_callproc + 856\n  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x0000000103ade4e4 PyCFuncPtr_call + 228\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Get leaf indices for adversarial training\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# booster = clf.get_booster()\u001b[39;00m\n\u001b[1;32m     73\u001b[0m num_trees \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1300\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m iteration \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1100\u001b[39m \u001b[38;5;66;03m#booster.best_iteration\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m leaf_indices \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mFEATURES\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Limit to the best number of trees\u001b[39;49;00m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m all_leaf_indices\u001b[38;5;241m.\u001b[39mappend(leaf_indices)\n\u001b[1;32m     80\u001b[0m all_races\u001b[38;5;241m.\u001b[39mappend(x_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace_group\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/xgboost/core.py:2384\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, output_margin, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   2382\u001b[0m shape \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mPOINTER(c_bst_ulong)()\n\u001b[1;32m   2383\u001b[0m dims \u001b[38;5;241m=\u001b[39m c_bst_ulong()\n\u001b[0;32m-> 2384\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2385\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterPredictFromDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2386\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_pystr_to_cstr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ai/lib/python3.8/site-packages/xgboost/core.py:284\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [18:24:14] /Users/runner/work/xgboost/xgboost/src/gbm/gbtree.h:123: Check failed: end <= model.BoostedRounds() (1100 vs. 1023) : Out of range for tree layers.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000013f7f8428 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x000000013f9ceb3c xgboost::gbm::detail::LayerToTree(xgboost::gbm::GBTreeModel const&, int, int) + 340\n  [bt] (2) 3   libxgboost.dylib                    0x000000013f9c7234 xgboost::gbm::GBTree::PredictLeaf(xgboost::DMatrix*, xgboost::HostDeviceVector<float>*, unsigned int, unsigned int) + 56\n  [bt] (3) 4   libxgboost.dylib                    0x000000013f9e4810 xgboost::LearnerImpl::Predict(std::__1::shared_ptr<xgboost::DMatrix>, bool, xgboost::HostDeviceVector<float>*, int, int, bool, bool, bool, bool, bool) + 460\n  [bt] (4) 5   libxgboost.dylib                    0x000000013f879058 XGBoosterPredictFromDMatrix + 864\n  [bt] (5) 6   libffi.8.dylib                      0x0000000103b0c04c ffi_call_SYSV + 76\n  [bt] (6) 7   libffi.8.dylib                      0x0000000103b09834 ffi_call_int + 1404\n  [bt] (7) 8   _ctypes.cpython-38-darwin.so        0x0000000103ae40ac _ctypes_callproc + 856\n  [bt] (8) 9   _ctypes.cpython-38-darwin.so        0x0000000103ade4e4 PyCFuncPtr_call + 228\n\n"
     ]
    }
   ],
   "source": [
    "# Prepare outoffold DataFrame to hold predictions and metadata\n",
    "oof_xgb = train[['kfold', 'ID', 'efs', 'efs_time', 'label', 'race_group']].copy()\n",
    "oof_xgb['prediction'] = 0.0\n",
    "feature_importances_xgb = pd.DataFrame({'feature': FEATURES})\n",
    "metric_df = []\n",
    "\n",
    "# Add these parameters at the top\n",
    "N_ITERATIONS = 3  # Number of adversarial+DRO updates\n",
    "ADVERSARY_STRENGTH = 0.7  # Higher = more race invariance\n",
    "DRO_STRENGTH = 0.3  # Higher = more focus on worst groups\n",
    "\n",
    "# Initialize sample weights and group weights\n",
    "sample_weights = np.ones(len(train))\n",
    "group_weights = {group: 1.0 for group in train['race_group'].unique()}\n",
    "\n",
    "# Modified training loop with adversarial+DRO\n",
    "for iteration in range(N_ITERATIONS):\n",
    "    print(f\"\\n=== Adversarial+DRO Iteration {iteration+1}/{N_ITERATIONS} ===\")\n",
    "    \n",
    "    oof_xgb = train[['kfold','ID','efs','efs_time','label','race_group']].copy()\n",
    "    oof_xgb['prediction'] = 0.0\n",
    "    metric_df = []\n",
    "    \n",
    "    # Store adversary training data across folds\n",
    "    all_train_indices = []  # Store indices of training data for each fold\n",
    "    all_leaf_indices = []\n",
    "    all_races = []\n",
    "    \n",
    "    for fold in range(skf.n_splits):\n",
    "        print(f\"\\nFold {fold+1}/{skf.n_splits}\")\n",
    "        \n",
    "        x_train = train[train.kfold != fold].copy()\n",
    "        x_valid = train[train.kfold == fold].copy()\n",
    "\n",
    "        y_train = x_train['label']\n",
    "        y_valid = x_valid['label']\n",
    "\n",
    "        # Store training indices for this fold\n",
    "        all_train_indices.append(x_train.index)\n",
    "        \n",
    "        # define two extra dataframe for the custom metric\n",
    "        ds_true = oof_xgb.loc[oof_xgb.kfold==fold, [\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy().reset_index(drop=True)\n",
    "        ds_pred = oof_xgb.loc[oof_xgb.kfold==fold, [\"ID\"]].copy().reset_index(drop=True)\n",
    "        \n",
    "        # Get current sample weights for training data\n",
    "        train_weights = sample_weights[x_train.index]\n",
    "\n",
    "        # Train model with current weights\n",
    "        clf = XGBRegressor(\n",
    "            tree_method=\"hist\",\n",
    "            max_depth=3,\n",
    "            colsample_bytree=0.5, \n",
    "            subsample=0.8, \n",
    "            n_estimators=10000,  \n",
    "            learning_rate=0.03,\n",
    "            early_stopping_rounds=100,\n",
    "            objective='reg:squarederror',\n",
    "            enable_categorical=True,\n",
    "            min_child_weight=5,\n",
    "            eval_metric=CIndexMetric_XGB,\n",
    "            disable_default_eval_metric=True\n",
    "        )\n",
    "        \n",
    "        clf.fit(\n",
    "            x_train[FEATURES], y_train,\n",
    "            sample_weight=train_weights,  # Apply current weights\n",
    "            eval_set=[(x_valid[FEATURES], y_valid)],\n",
    "            verbose=500\n",
    "        )\n",
    "        \n",
    "        # Get leaf indices for adversarial training\n",
    "        # booster = clf.get_booster()\n",
    "        num_trees = 1300 if iteration == 0 else 1100 #booster.best_iteration\n",
    "        leaf_indices = clf.get_booster().predict(\n",
    "            xgb.DMatrix(x_train[FEATURES], enable_categorical=True),\n",
    "            pred_leaf=True,\n",
    "            iteration_range=(0, num_trees)  # Limit to the best number of trees\n",
    "        )\n",
    "        all_leaf_indices.append(leaf_indices)\n",
    "        all_races.append(x_train['race_group'])\n",
    "        \n",
    "        # Store predictions\n",
    "        preds_valid = clf.predict(x_valid[FEATURES])\n",
    "        oof_xgb.loc[oof_xgb.kfold==fold, 'prediction'] = preds_valid\n",
    "        \n",
    "        clf.save_model(f\"xgb/xgb_model_deepseek_adversarial_dro_{iteration}_{fold}.bin\")\n",
    "\n",
    "        # Calculate fold metrics\n",
    "        y_true = oof_xgb.loc[oof_xgb.kfold==fold, [\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "        y_pred = oof_xgb.loc[oof_xgb.kfold==fold, [\"ID\",\"prediction\"]].copy()\n",
    "        _, metric_dict = custom_score(y_true, y_pred, \"ID\", print_info=True)\n",
    "        metric_df.append(metric_dict)\n",
    "    \n",
    "    # After all folds: Update weights -------------------------------------------------\n",
    "    \n",
    "    # 1. Adversarial weight update\n",
    "    # Train adversary on leaf indices from all folds\n",
    "    adversary = XGBClassifier(\n",
    "        tree_method='hist',\n",
    "        max_depth=3,\n",
    "        enable_categorical=True,\n",
    "        n_estimators=200\n",
    "    )\n",
    "    \n",
    "    # Prepare adversarial training data\n",
    "    adv_features = np.concatenate(all_leaf_indices)\n",
    "    adv_target = pd.concat(all_races).reset_index(drop=True)\n",
    "    \n",
    "    # Encode race labels into numeric values\n",
    "    label_encoder = LabelEncoder()\n",
    "    adv_target_encoded = label_encoder.fit_transform(adv_target)\n",
    "\n",
    "    # Train race predictor\n",
    "    adversary.fit(adv_features, adv_target_encoded)\n",
    "\n",
    "    adversary.save_model(f\"xgb/xgb_model_deepseek_adversary_{iteration}.bin\")\n",
    "    \n",
    "    # Calculate race predictability\n",
    "    race_probs = adversary.predict_proba(adv_features)\n",
    "    correct_probs = race_probs[np.arange(len(adv_target)), adv_target.cat.codes]\n",
    "    adv_weights = 1 / (correct_probs + 1e-8)  # Downweight predictable samples\n",
    "    \n",
    "    # Map back to original indices\n",
    "    adv_weight_df = pd.DataFrame({\n",
    "        'index': np.concatenate(all_train_indices),  # Use stored training indices\n",
    "        'adv_weight': adv_weights\n",
    "    })\n",
    "    adv_weight_df = (\n",
    "    adv_weight_df\n",
    "    .groupby('index')['adv_weight'].mean()  # Aggregate duplicates (mean/sum)\n",
    "    .reindex(train.index)                   # Align with original training data\n",
    "    .fillna(1.0)                            # Fill missing values\n",
    "    .rename('adv_weight')                   # Rename for clarity\n",
    "    .to_frame()                             # Convert to DataFrame\n",
    "    )\n",
    "\n",
    "\n",
    "    # 2. Group DRO weight update\n",
    "    # Calculate group performance from OOF predictions\n",
    "    group_cindex = {}\n",
    "    for group in train['race_group'].unique():\n",
    "        mask = (oof_xgb['race_group'] == group)\n",
    "        if mask.sum() > 0:\n",
    "            cidx = concordance_index(\n",
    "                oof_xgb.loc[mask, 'efs_time'],\n",
    "                -oof_xgb.loc[mask, 'prediction'],\n",
    "                oof_xgb.loc[mask, 'efs']\n",
    "            )\n",
    "            group_cindex[group] = cidx\n",
    "    \n",
    "    # Calculate group weights inversely proportional to performance\n",
    "    min_cindex = min(group_cindex.values())\n",
    "    group_weights = {\n",
    "        group: (min_cindex / (cidx + 1e-8)) * DRO_STRENGTH\n",
    "        for group, cidx in group_cindex.items()\n",
    "    }\n",
    "    \n",
    "    # 3. Combine weights\n",
    "    sample_weights = (\n",
    "        adv_weight_df['adv_weight'].values * ADVERSARY_STRENGTH +\n",
    "        train['race_group'].map(group_weights).astype(float) * DRO_STRENGTH\n",
    "    )\n",
    "    sample_weights = sample_weights / sample_weights.mean()  # Normalize\n",
    "\n",
    "# Final training with updated weights -------------------------------------------------\n",
    "print(\"\\n=== Final Training ===\")\n",
    "display_overall(pd.DataFrame(metric_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_test_set(test_set, model_prefix, skf, FEATURES, custom_score, dataset_name=\"test set\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given test set (imbalanced or balanced).\n",
    "    \n",
    "    Parameters:\n",
    "        test_set (pd.DataFrame): The test set to evaluate.\n",
    "        model_prefix (str): Prefix for the saved model filenames.\n",
    "        skf (StratifiedKFold): Cross-validation object to determine the number of folds.\n",
    "        FEATURES (list): List of feature columns.\n",
    "        custom_score (function): Function to compute custom evaluation metric.\n",
    "        dataset_name (str): Name of the dataset for logging purposes.\n",
    "    \n",
    "    Returns:\n",
    "        None (prints evaluation results)\n",
    "    \"\"\"\n",
    "    print(f\"Evaluating on {dataset_name}...\")\n",
    "\n",
    "    # Ensure the test set has the required feature columns\n",
    "    if not set(FEATURES).issubset(test_set.columns):\n",
    "        raise ValueError(f\"{dataset_name} does not have all required feature columns.\")\n",
    "\n",
    "    # Initialize an array to accumulate predictions from each fold\n",
    "    test_predictions = np.zeros(len(test_set))\n",
    "\n",
    "    # Initialize a dictionary to store the evaluation metric for each fold\n",
    "    metric_df = []\n",
    "\n",
    "    # Loop over folds, load each saved model, and predict on the test set\n",
    "    for fold in range(skf.n_splits):\n",
    "        model_filename = f\"xgb/{model_prefix}_{fold}.bin\"\n",
    "        clf = XGBRegressor()  # We only use this to load the saved booster\n",
    "        clf.load_model(model_filename)\n",
    "        fold_pred = clf.predict(test_set[FEATURES])\n",
    "        test_set[f'prediction_{fold}'] = fold_pred\n",
    "\n",
    "        # If labels exist, compute the custom metric for this fold\n",
    "        if \"label\" in test_set.columns:\n",
    "            y_true_test = test_set[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy().reset_index(drop=True)\n",
    "            y_pred_test = test_set[[\"ID\", f\"prediction_{fold}\"]].copy().reset_index(drop=True)\n",
    "            m, metric_dict = custom_score(y_true_test, y_pred_test, \"ID\", print_info=True, prediction_label=f\"prediction_{fold}\")\n",
    "            print(f\"{dataset_name} evaluation metric for fold {fold}:\", metric_dict)\n",
    "            metric_df.append(metric_dict)\n",
    "\n",
    "        test_predictions += fold_pred\n",
    "\n",
    "    # Average the predictions across folds\n",
    "    test_predictions /= skf.n_splits\n",
    "    test_set['ensemble_prediction'] = test_predictions\n",
    "\n",
    "    print('\\nENSEMBLE:')\n",
    "    # If labels exist, compute the custom metric for an ensemble\n",
    "    if \"label\" in test_set.columns:\n",
    "        y_true_test = test_set[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy().reset_index(drop=True)\n",
    "        y_pred_test = test_set[[\"ID\", \"ensemble_prediction\"]].copy().reset_index(drop=True)\n",
    "        m, ensemble_metric_dict = custom_score(y_true_test, y_pred_test, \"ID\", print_info=True, prediction_label=\"ensemble_prediction\")\n",
    "        print(f\"{dataset_name} evaluation metric:\", metric_dict)\n",
    "    else:\n",
    "        print(f\"{dataset_name} predictions computed. No labels available for evaluation.\")\n",
    "    return ensemble_metric_dict, metric_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on full test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upweight minority and ignore white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on balanced test set...\n",
      "\u001b[32m\u001b[1m# c-index=0.6546, mean=0.6657 std=0.0111\u001b[0m\n",
      "balanced test set evaluation metric for fold 0: {'American Indian or Alaska Native': 0.6852392464534963, 'Asian': 0.6699527924558063, 'Black or African-American': 0.6523944502461584, 'More than one race': 0.6659624603883968, 'Native Hawaiian or other Pacific Islander': 0.6529193004271585, 'White': 0.6679261620813162}\n",
      "\u001b[32m\u001b[1m# c-index=0.6534, mean=0.6671 std=0.0137\u001b[0m\n",
      "balanced test set evaluation metric for fold 1: {'American Indian or Alaska Native': 0.6915568124800437, 'Asian': 0.6676205820385998, 'Black or African-American': 0.6535666332772107, 'More than one race': 0.6682608039559368, 'Native Hawaiian or other Pacific Islander': 0.6493270238218599, 'White': 0.6720588814106349}\n",
      "\u001b[32m\u001b[1m# c-index=0.6583, mean=0.6680 std=0.0096\u001b[0m\n",
      "balanced test set evaluation metric for fold 2: {'American Indian or Alaska Native': 0.6834032750992108, 'Asian': 0.6704935948713904, 'Black or African-American': 0.657019245114128, 'More than one race': 0.6656606576977098, 'Native Hawaiian or other Pacific Islander': 0.6562352480628187, 'White': 0.6750206635966466}\n",
      "\u001b[32m\u001b[1m# c-index=0.6532, mean=0.6654 std=0.0122\u001b[0m\n",
      "balanced test set evaluation metric for fold 3: {'American Indian or Alaska Native': 0.6867787255393879, 'Asian': 0.6671023130569983, 'Black or African-American': 0.6477057181219497, 'More than one race': 0.663931096124157, 'Native Hawaiian or other Pacific Islander': 0.656246761769887, 'White': 0.6706025898374464}\n",
      "\u001b[32m\u001b[1m# c-index=0.6543, mean=0.6681 std=0.0138\u001b[0m\n",
      "balanced test set evaluation metric for fold 4: {'American Indian or Alaska Native': 0.694282260639511, 'Asian': 0.6691641222664128, 'Black or African-American': 0.6533641652991198, 'More than one race': 0.6691081730490197, 'Native Hawaiian or other Pacific Islander': 0.6527005399928615, 'White': 0.6700614004014641}\n",
      "\n",
      "ENSEMBLE:\n",
      "\u001b[32m\u001b[1m# c-index=0.6572, mean=0.6692 std=0.0121\u001b[0m\n",
      "balanced test set evaluation metric: {'American Indian or Alaska Native': 0.694282260639511, 'Asian': 0.6691641222664128, 'Black or African-American': 0.6533641652991198, 'More than one race': 0.6691081730490197, 'Native Hawaiian or other Pacific Islander': 0.6527005399928615, 'White': 0.6700614004014641}\n"
     ]
    }
   ],
   "source": [
    "ensemble_balanced_metric_dict, balanced_metric_dicts = evaluate_test_set(test_balanced, \n",
    "                                                                         \"xgb_model_upweight_minority_ignore_white\", skf, FEATURES, custom_score, dataset_name=\"balanced test set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a9f90_row0_col0 {\n",
       "  background-color: #ce31ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row0_col1 {\n",
       "  background-color: #f10eff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row0_col2 {\n",
       "  background-color: #c43bff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row0_col3 {\n",
       "  background-color: #d629ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row0_col4 {\n",
       "  background-color: #ff00ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row0_col5 {\n",
       "  background-color: #de21ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row1_col0, #T_a9f90_row5_col4 {\n",
       "  background-color: #7a85ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row1_col1 {\n",
       "  background-color: #6d92ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row1_col2, #T_a9f90_row5_col3 {\n",
       "  background-color: #7d82ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row1_col3 {\n",
       "  background-color: #6a95ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row1_col4, #T_a9f90_row3_col4 {\n",
       "  background-color: #758aff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row1_col5 {\n",
       "  background-color: #748bff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row2_col0 {\n",
       "  background-color: #19e6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9f90_row2_col1 {\n",
       "  background-color: #20dfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9f90_row2_col2 {\n",
       "  background-color: #33ccff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9f90_row2_col3 {\n",
       "  background-color: #00ffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9f90_row2_col4, #T_a9f90_row4_col5 {\n",
       "  background-color: #1fe0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9f90_row2_col5, #T_a9f90_row4_col0 {\n",
       "  background-color: #1ce3ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9f90_row3_col0 {\n",
       "  background-color: #649bff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row3_col1 {\n",
       "  background-color: #708fff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row3_col2 {\n",
       "  background-color: #629dff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row3_col3 {\n",
       "  background-color: #59a6ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row3_col5 {\n",
       "  background-color: #6798ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row4_col1 {\n",
       "  background-color: #08f7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9f90_row4_col2, #T_a9f90_row4_col3 {\n",
       "  background-color: #2ed1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9f90_row4_col4 {\n",
       "  background-color: #1be4ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_a9f90_row5_col0 {\n",
       "  background-color: #6f90ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row5_col1 {\n",
       "  background-color: #857aff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row5_col2 {\n",
       "  background-color: #9669ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_a9f90_row5_col5 {\n",
       "  background-color: #807fff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a9f90\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a9f90_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_a9f90_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_a9f90_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_a9f90_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_a9f90_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_a9f90_level0_col5\" class=\"col_heading level0 col5\" >Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a9f90_level0_row0\" class=\"row_heading level0 row0\" >American Indian or Alaska Native</th>\n",
       "      <td id=\"T_a9f90_row0_col0\" class=\"data row0 col0\" >0.6852</td>\n",
       "      <td id=\"T_a9f90_row0_col1\" class=\"data row0 col1\" >0.6916</td>\n",
       "      <td id=\"T_a9f90_row0_col2\" class=\"data row0 col2\" >0.6834</td>\n",
       "      <td id=\"T_a9f90_row0_col3\" class=\"data row0 col3\" >0.6868</td>\n",
       "      <td id=\"T_a9f90_row0_col4\" class=\"data row0 col4\" >0.6943</td>\n",
       "      <td id=\"T_a9f90_row0_col5\" class=\"data row0 col5\" >0.6883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9f90_level0_row1\" class=\"row_heading level0 row1\" >Asian</th>\n",
       "      <td id=\"T_a9f90_row1_col0\" class=\"data row1 col0\" >0.6700</td>\n",
       "      <td id=\"T_a9f90_row1_col1\" class=\"data row1 col1\" >0.6676</td>\n",
       "      <td id=\"T_a9f90_row1_col2\" class=\"data row1 col2\" >0.6705</td>\n",
       "      <td id=\"T_a9f90_row1_col3\" class=\"data row1 col3\" >0.6671</td>\n",
       "      <td id=\"T_a9f90_row1_col4\" class=\"data row1 col4\" >0.6692</td>\n",
       "      <td id=\"T_a9f90_row1_col5\" class=\"data row1 col5\" >0.6689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9f90_level0_row2\" class=\"row_heading level0 row2\" >Black or African-American</th>\n",
       "      <td id=\"T_a9f90_row2_col0\" class=\"data row2 col0\" >0.6524</td>\n",
       "      <td id=\"T_a9f90_row2_col1\" class=\"data row2 col1\" >0.6536</td>\n",
       "      <td id=\"T_a9f90_row2_col2\" class=\"data row2 col2\" >0.6570</td>\n",
       "      <td id=\"T_a9f90_row2_col3\" class=\"data row2 col3\" >0.6477</td>\n",
       "      <td id=\"T_a9f90_row2_col4\" class=\"data row2 col4\" >0.6534</td>\n",
       "      <td id=\"T_a9f90_row2_col5\" class=\"data row2 col5\" >0.6528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9f90_level0_row3\" class=\"row_heading level0 row3\" >More than one race</th>\n",
       "      <td id=\"T_a9f90_row3_col0\" class=\"data row3 col0\" >0.6660</td>\n",
       "      <td id=\"T_a9f90_row3_col1\" class=\"data row3 col1\" >0.6683</td>\n",
       "      <td id=\"T_a9f90_row3_col2\" class=\"data row3 col2\" >0.6657</td>\n",
       "      <td id=\"T_a9f90_row3_col3\" class=\"data row3 col3\" >0.6639</td>\n",
       "      <td id=\"T_a9f90_row3_col4\" class=\"data row3 col4\" >0.6691</td>\n",
       "      <td id=\"T_a9f90_row3_col5\" class=\"data row3 col5\" >0.6666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9f90_level0_row4\" class=\"row_heading level0 row4\" >Native Hawaiian or other Pacific Islander</th>\n",
       "      <td id=\"T_a9f90_row4_col0\" class=\"data row4 col0\" >0.6529</td>\n",
       "      <td id=\"T_a9f90_row4_col1\" class=\"data row4 col1\" >0.6493</td>\n",
       "      <td id=\"T_a9f90_row4_col2\" class=\"data row4 col2\" >0.6562</td>\n",
       "      <td id=\"T_a9f90_row4_col3\" class=\"data row4 col3\" >0.6562</td>\n",
       "      <td id=\"T_a9f90_row4_col4\" class=\"data row4 col4\" >0.6527</td>\n",
       "      <td id=\"T_a9f90_row4_col5\" class=\"data row4 col5\" >0.6535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9f90_level0_row5\" class=\"row_heading level0 row5\" >White</th>\n",
       "      <td id=\"T_a9f90_row5_col0\" class=\"data row5 col0\" >0.6679</td>\n",
       "      <td id=\"T_a9f90_row5_col1\" class=\"data row5 col1\" >0.6721</td>\n",
       "      <td id=\"T_a9f90_row5_col2\" class=\"data row5 col2\" >0.6750</td>\n",
       "      <td id=\"T_a9f90_row5_col3\" class=\"data row5 col3\" >0.6706</td>\n",
       "      <td id=\"T_a9f90_row5_col4\" class=\"data row5 col4\" >0.6701</td>\n",
       "      <td id=\"T_a9f90_row5_col5\" class=\"data row5 col5\" >0.6711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9f90_level0_foot0_row0\" class=\"foot0_row_heading level0 foot0_row0\" >mean</th>\n",
       "      <td id=\"T_a9f90_foot0_row0_col0\" class=\"foot0_data foot0_row0 col0\" >0.666</td>\n",
       "      <td id=\"T_a9f90_foot0_row0_col1\" class=\"foot0_data foot0_row0 col1\" >0.667</td>\n",
       "      <td id=\"T_a9f90_foot0_row0_col2\" class=\"foot0_data foot0_row0 col2\" >0.668</td>\n",
       "      <td id=\"T_a9f90_foot0_row0_col3\" class=\"foot0_data foot0_row0 col3\" >0.665</td>\n",
       "      <td id=\"T_a9f90_foot0_row0_col4\" class=\"foot0_data foot0_row0 col4\" >0.668</td>\n",
       "      <td id=\"T_a9f90_foot0_row0_col5\" class=\"foot0_data foot0_row0 col5\" >0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9f90_level0_foot0_row1\" class=\"foot0_row_heading level0 foot0_row1\" >std</th>\n",
       "      <td id=\"T_a9f90_foot0_row1_col0\" class=\"foot0_data foot0_row1 col0\" >0.011</td>\n",
       "      <td id=\"T_a9f90_foot0_row1_col1\" class=\"foot0_data foot0_row1 col1\" >0.014</td>\n",
       "      <td id=\"T_a9f90_foot0_row1_col2\" class=\"foot0_data foot0_row1 col2\" >0.010</td>\n",
       "      <td id=\"T_a9f90_foot0_row1_col3\" class=\"foot0_data foot0_row1 col3\" >0.012</td>\n",
       "      <td id=\"T_a9f90_foot0_row1_col4\" class=\"foot0_data foot0_row1 col4\" >0.014</td>\n",
       "      <td id=\"T_a9f90_foot0_row1_col5\" class=\"foot0_data foot0_row1 col5\" >0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a9f90_level0_foot0_row2\" class=\"foot0_row_heading level0 foot0_row2\" >score</th>\n",
       "      <td id=\"T_a9f90_foot0_row2_col0\" class=\"foot0_data foot0_row2 col0\" >0.655</td>\n",
       "      <td id=\"T_a9f90_foot0_row2_col1\" class=\"foot0_data foot0_row2 col1\" >0.653</td>\n",
       "      <td id=\"T_a9f90_foot0_row2_col2\" class=\"foot0_data foot0_row2 col2\" >0.658</td>\n",
       "      <td id=\"T_a9f90_foot0_row2_col3\" class=\"foot0_data foot0_row2 col3\" >0.653</td>\n",
       "      <td id=\"T_a9f90_foot0_row2_col4\" class=\"foot0_data foot0_row2 col4\" >0.654</td>\n",
       "      <td id=\"T_a9f90_foot0_row2_col5\" class=\"foot0_data foot0_row2 col5\" >0.655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x358b208b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_overall(pd.DataFrame(balanced_metric_dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upweight minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on balanced test set...\n",
      "\u001b[32m\u001b[1m# c-index=0.6552, mean=0.6668 std=0.0116\u001b[0m\n",
      "balanced test set evaluation metric for fold 0: {'American Indian or Alaska Native': 0.687531359759157, 'Asian': 0.6699753258897889, 'Black or African-American': 0.6549519404957269, 'More than one race': 0.6631998049890306, 'Native Hawaiian or other Pacific Islander': 0.6531726019826604, 'White': 0.6718719250600228}\n",
      "\u001b[32m\u001b[1m# c-index=0.6543, mean=0.6672 std=0.0129\u001b[0m\n",
      "balanced test set evaluation metric for fold 1: {'American Indian or Alaska Native': 0.6906787392236464, 'Asian': 0.667361447547799, 'Black or African-American': 0.6551970333113105, 'More than one race': 0.6680634714274106, 'Native Hawaiian or other Pacific Islander': 0.6504323397004134, 'White': 0.6716062502459952}\n",
      "\u001b[32m\u001b[1m# c-index=0.6554, mean=0.6666 std=0.0112\u001b[0m\n",
      "balanced test set evaluation metric for fold 2: {'American Indian or Alaska Native': 0.6830383615381107, 'Asian': 0.6690401883795081, 'Black or African-American': 0.6528633234585793, 'More than one race': 0.6660088915715795, 'Native Hawaiian or other Pacific Islander': 0.6525393480939058, 'White': 0.6759948045814146}\n",
      "\u001b[32m\u001b[1m# c-index=0.6518, mean=0.6647 std=0.0130\u001b[0m\n",
      "balanced test set evaluation metric for fold 3: {'American Indian or Alaska Native': 0.6860717055147562, 'Asian': 0.6697161913989883, 'Black or African-American': 0.6475405468766651, 'More than one race': 0.6631301582142567, 'Native Hawaiian or other Pacific Islander': 0.6509274291043488, 'White': 0.6708879442673279}\n",
      "\u001b[32m\u001b[1m# c-index=0.6545, mean=0.6679 std=0.0134\u001b[0m\n",
      "balanced test set evaluation metric for fold 4: {'American Indian or Alaska Native': 0.6927313780048351, 'Asian': 0.6696260576630576, 'Black or African-American': 0.6535240084397178, 'More than one race': 0.6684117053012804, 'Native Hawaiian or other Pacific Islander': 0.6524817795585645, 'White': 0.6705140315661038}\n",
      "\n",
      "ENSEMBLE:\n",
      "\u001b[32m\u001b[1m# c-index=0.6566, mean=0.6690 std=0.0124\u001b[0m\n",
      "balanced test set evaluation metric: {'American Indian or Alaska Native': 0.6927313780048351, 'Asian': 0.6696260576630576, 'Black or African-American': 0.6535240084397178, 'More than one race': 0.6684117053012804, 'Native Hawaiian or other Pacific Islander': 0.6524817795585645, 'White': 0.6705140315661038}\n"
     ]
    }
   ],
   "source": [
    "ensemble_balanced_metric_dict, balanced_metric_dicts = evaluate_test_set(test_balanced, \n",
    "                                                                         \"xgb_model_downweight_majority\", skf, FEATURES, custom_score, dataset_name=\"balanced test set\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on imbalanced test subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upweight minority ignore white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on imbalanced test set...\n",
      "\u001b[32m\u001b[1m# c-index=0.5780, mean=0.6338 std=0.0558\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 0: {'American Indian or Alaska Native': 0.6842818428184282, 'Asian': 0.6410490307867731, 'Black or African-American': 0.6406561737973842, 'More than one race': 0.5137686860739575, 'Native Hawaiian or other Pacific Islander': 0.6549925484351714, 'White': 0.6679261620813162}\n",
      "\u001b[32m\u001b[1m# c-index=0.5895, mean=0.6402 std=0.0507\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 1: {'American Indian or Alaska Native': 0.6907181571815718, 'Asian': 0.6474344355758267, 'Black or African-American': 0.6372940220202468, 'More than one race': 0.5334382376081825, 'Native Hawaiian or other Pacific Islander': 0.6602086438152012, 'White': 0.6720588814106349}\n",
      "\u001b[32m\u001b[1m# c-index=0.5820, mean=0.6373 std=0.0553\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 2: {'American Indian or Alaska Native': 0.6747967479674797, 'Asian': 0.6419612314709237, 'Black or African-American': 0.6482302519766496, 'More than one race': 0.5169158143194336, 'Native Hawaiian or other Pacific Islander': 0.6669150521609538, 'White': 0.6750206635966466}\n",
      "\u001b[32m\u001b[1m# c-index=0.5814, mean=0.6385 std=0.0571\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 3: {'American Indian or Alaska Native': 0.6869918699186992, 'Asian': 0.6481185860889396, 'Black or African-American': 0.6369615015148157, 'More than one race': 0.5161290322580645, 'Native Hawaiian or other Pacific Islander': 0.6721311475409836, 'White': 0.6706025898374464}\n",
      "\u001b[32m\u001b[1m# c-index=0.5857, mean=0.6367 std=0.0510\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 4: {'American Indian or Alaska Native': 0.6788617886178862, 'Asian': 0.6474344355758267, 'Black or African-American': 0.6410995344712924, 'More than one race': 0.5263571990558615, 'Native Hawaiian or other Pacific Islander': 0.6564828614008942, 'White': 0.6700614004014641}\n",
      "\n",
      "ENSEMBLE:\n",
      "\u001b[32m\u001b[1m# c-index=0.5839, mean=0.6388 std=0.0549\u001b[0m\n",
      "imbalanced test set evaluation metric: {'American Indian or Alaska Native': 0.6788617886178862, 'Asian': 0.6474344355758267, 'Black or African-American': 0.6410995344712924, 'More than one race': 0.5263571990558615, 'Native Hawaiian or other Pacific Islander': 0.6564828614008942, 'White': 0.6700614004014641}\n"
     ]
    }
   ],
   "source": [
    "ensemble_imbalanced_metric_dict, imbalanced_metric_dicts = evaluate_test_set(test, \"xgb_model_upweight_minority_ignore_white\", skf, FEATURES, custom_score, dataset_name=\"imbalanced test set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_54101_row0_col0 {\n",
       "  background-color: #f609ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row0_col1 {\n",
       "  background-color: #ff00ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row0_col2 {\n",
       "  background-color: #e817ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row0_col3 {\n",
       "  background-color: #fa05ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row0_col4 {\n",
       "  background-color: #ee11ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row0_col5 {\n",
       "  background-color: #f50aff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row1_col0, #T_54101_row2_col4 {\n",
       "  background-color: #b847ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row1_col1, #T_54101_row1_col4 {\n",
       "  background-color: #c13eff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row1_col2 {\n",
       "  background-color: #b946ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row1_col3, #T_54101_row2_col2 {\n",
       "  background-color: #c23dff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row1_col5 {\n",
       "  background-color: #be41ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row2_col0, #T_54101_row2_col5 {\n",
       "  background-color: #b748ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row2_col1, #T_54101_row2_col3 {\n",
       "  background-color: #b24dff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row3_col0 {\n",
       "  background-color: #00ffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_54101_row3_col1 {\n",
       "  background-color: #1ce3ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_54101_row3_col2 {\n",
       "  background-color: #04fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_54101_row3_col3 {\n",
       "  background-color: #03fcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_54101_row3_col4 {\n",
       "  background-color: #12edff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_54101_row3_col5 {\n",
       "  background-color: #0af5ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_54101_row4_col0 {\n",
       "  background-color: #cc33ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row4_col1 {\n",
       "  background-color: #d32cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row4_col2 {\n",
       "  background-color: #dd22ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row4_col3, #T_54101_row5_col1 {\n",
       "  background-color: #e51aff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row4_col4 {\n",
       "  background-color: #ce31ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row4_col5 {\n",
       "  background-color: #d629ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row5_col0 {\n",
       "  background-color: #df20ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row5_col2 {\n",
       "  background-color: #e916ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row5_col3, #T_54101_row5_col4 {\n",
       "  background-color: #e21dff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_54101_row5_col5 {\n",
       "  background-color: #e31cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_54101\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_54101_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_54101_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_54101_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_54101_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_54101_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_54101_level0_col5\" class=\"col_heading level0 col5\" >Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_54101_level0_row0\" class=\"row_heading level0 row0\" >American Indian or Alaska Native</th>\n",
       "      <td id=\"T_54101_row0_col0\" class=\"data row0 col0\" >0.6843</td>\n",
       "      <td id=\"T_54101_row0_col1\" class=\"data row0 col1\" >0.6907</td>\n",
       "      <td id=\"T_54101_row0_col2\" class=\"data row0 col2\" >0.6748</td>\n",
       "      <td id=\"T_54101_row0_col3\" class=\"data row0 col3\" >0.6870</td>\n",
       "      <td id=\"T_54101_row0_col4\" class=\"data row0 col4\" >0.6789</td>\n",
       "      <td id=\"T_54101_row0_col5\" class=\"data row0 col5\" >0.6831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54101_level0_row1\" class=\"row_heading level0 row1\" >Asian</th>\n",
       "      <td id=\"T_54101_row1_col0\" class=\"data row1 col0\" >0.6410</td>\n",
       "      <td id=\"T_54101_row1_col1\" class=\"data row1 col1\" >0.6474</td>\n",
       "      <td id=\"T_54101_row1_col2\" class=\"data row1 col2\" >0.6420</td>\n",
       "      <td id=\"T_54101_row1_col3\" class=\"data row1 col3\" >0.6481</td>\n",
       "      <td id=\"T_54101_row1_col4\" class=\"data row1 col4\" >0.6474</td>\n",
       "      <td id=\"T_54101_row1_col5\" class=\"data row1 col5\" >0.6452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54101_level0_row2\" class=\"row_heading level0 row2\" >Black or African-American</th>\n",
       "      <td id=\"T_54101_row2_col0\" class=\"data row2 col0\" >0.6407</td>\n",
       "      <td id=\"T_54101_row2_col1\" class=\"data row2 col1\" >0.6373</td>\n",
       "      <td id=\"T_54101_row2_col2\" class=\"data row2 col2\" >0.6482</td>\n",
       "      <td id=\"T_54101_row2_col3\" class=\"data row2 col3\" >0.6370</td>\n",
       "      <td id=\"T_54101_row2_col4\" class=\"data row2 col4\" >0.6411</td>\n",
       "      <td id=\"T_54101_row2_col5\" class=\"data row2 col5\" >0.6408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54101_level0_row3\" class=\"row_heading level0 row3\" >More than one race</th>\n",
       "      <td id=\"T_54101_row3_col0\" class=\"data row3 col0\" >0.5138</td>\n",
       "      <td id=\"T_54101_row3_col1\" class=\"data row3 col1\" >0.5334</td>\n",
       "      <td id=\"T_54101_row3_col2\" class=\"data row3 col2\" >0.5169</td>\n",
       "      <td id=\"T_54101_row3_col3\" class=\"data row3 col3\" >0.5161</td>\n",
       "      <td id=\"T_54101_row3_col4\" class=\"data row3 col4\" >0.5264</td>\n",
       "      <td id=\"T_54101_row3_col5\" class=\"data row3 col5\" >0.5213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54101_level0_row4\" class=\"row_heading level0 row4\" >Native Hawaiian or other Pacific Islander</th>\n",
       "      <td id=\"T_54101_row4_col0\" class=\"data row4 col0\" >0.6550</td>\n",
       "      <td id=\"T_54101_row4_col1\" class=\"data row4 col1\" >0.6602</td>\n",
       "      <td id=\"T_54101_row4_col2\" class=\"data row4 col2\" >0.6669</td>\n",
       "      <td id=\"T_54101_row4_col3\" class=\"data row4 col3\" >0.6721</td>\n",
       "      <td id=\"T_54101_row4_col4\" class=\"data row4 col4\" >0.6565</td>\n",
       "      <td id=\"T_54101_row4_col5\" class=\"data row4 col5\" >0.6621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54101_level0_row5\" class=\"row_heading level0 row5\" >White</th>\n",
       "      <td id=\"T_54101_row5_col0\" class=\"data row5 col0\" >0.6679</td>\n",
       "      <td id=\"T_54101_row5_col1\" class=\"data row5 col1\" >0.6721</td>\n",
       "      <td id=\"T_54101_row5_col2\" class=\"data row5 col2\" >0.6750</td>\n",
       "      <td id=\"T_54101_row5_col3\" class=\"data row5 col3\" >0.6706</td>\n",
       "      <td id=\"T_54101_row5_col4\" class=\"data row5 col4\" >0.6701</td>\n",
       "      <td id=\"T_54101_row5_col5\" class=\"data row5 col5\" >0.6711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54101_level0_foot0_row0\" class=\"foot0_row_heading level0 foot0_row0\" >mean</th>\n",
       "      <td id=\"T_54101_foot0_row0_col0\" class=\"foot0_data foot0_row0 col0\" >0.634</td>\n",
       "      <td id=\"T_54101_foot0_row0_col1\" class=\"foot0_data foot0_row0 col1\" >0.640</td>\n",
       "      <td id=\"T_54101_foot0_row0_col2\" class=\"foot0_data foot0_row0 col2\" >0.637</td>\n",
       "      <td id=\"T_54101_foot0_row0_col3\" class=\"foot0_data foot0_row0 col3\" >0.638</td>\n",
       "      <td id=\"T_54101_foot0_row0_col4\" class=\"foot0_data foot0_row0 col4\" >0.637</td>\n",
       "      <td id=\"T_54101_foot0_row0_col5\" class=\"foot0_data foot0_row0 col5\" >0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54101_level0_foot0_row1\" class=\"foot0_row_heading level0 foot0_row1\" >std</th>\n",
       "      <td id=\"T_54101_foot0_row1_col0\" class=\"foot0_data foot0_row1 col0\" >0.056</td>\n",
       "      <td id=\"T_54101_foot0_row1_col1\" class=\"foot0_data foot0_row1 col1\" >0.051</td>\n",
       "      <td id=\"T_54101_foot0_row1_col2\" class=\"foot0_data foot0_row1 col2\" >0.055</td>\n",
       "      <td id=\"T_54101_foot0_row1_col3\" class=\"foot0_data foot0_row1 col3\" >0.057</td>\n",
       "      <td id=\"T_54101_foot0_row1_col4\" class=\"foot0_data foot0_row1 col4\" >0.051</td>\n",
       "      <td id=\"T_54101_foot0_row1_col5\" class=\"foot0_data foot0_row1 col5\" >0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54101_level0_foot0_row2\" class=\"foot0_row_heading level0 foot0_row2\" >score</th>\n",
       "      <td id=\"T_54101_foot0_row2_col0\" class=\"foot0_data foot0_row2 col0\" >0.578</td>\n",
       "      <td id=\"T_54101_foot0_row2_col1\" class=\"foot0_data foot0_row2 col1\" >0.589</td>\n",
       "      <td id=\"T_54101_foot0_row2_col2\" class=\"foot0_data foot0_row2 col2\" >0.582</td>\n",
       "      <td id=\"T_54101_foot0_row2_col3\" class=\"foot0_data foot0_row2 col3\" >0.581</td>\n",
       "      <td id=\"T_54101_foot0_row2_col4\" class=\"foot0_data foot0_row2 col4\" >0.586</td>\n",
       "      <td id=\"T_54101_foot0_row2_col5\" class=\"foot0_data foot0_row2 col5\" >0.583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x155b72a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_overall(pd.DataFrame(imbalanced_metric_dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upweight minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on imbalanced test set...\n",
      "\u001b[32m\u001b[1m# c-index=0.5733, mean=0.6343 std=0.0609\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 0: {'American Indian or Alaska Native': 0.6832655826558266, 'Asian': 0.6483466362599772, 'Black or African-American': 0.6458656617158058, 'More than one race': 0.5011801730920535, 'Native Hawaiian or other Pacific Islander': 0.6549925484351714, 'White': 0.6718719250600228}\n",
      "\u001b[32m\u001b[1m# c-index=0.5935, mean=0.6410 std=0.0475\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 1: {'American Indian or Alaska Native': 0.6876693766937669, 'Asian': 0.6501710376282782, 'Black or African-American': 0.6393999852213109, 'More than one race': 0.5405192761605035, 'Native Hawaiian or other Pacific Islander': 0.6564828614008942, 'White': 0.6716062502459952}\n",
      "\u001b[32m\u001b[1m# c-index=0.5793, mean=0.6357 std=0.0564\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 2: {'American Indian or Alaska Native': 0.6744579945799458, 'Asian': 0.6433295324971494, 'Black or African-American': 0.6443877928027784, 'More than one race': 0.5129819040125885, 'Native Hawaiian or other Pacific Islander': 0.6631892697466468, 'White': 0.6759948045814146}\n",
      "\u001b[32m\u001b[1m# c-index=0.5788, mean=0.6354 std=0.0566\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 3: {'American Indian or Alaska Native': 0.6941056910569106, 'Asian': 0.6481185860889396, 'Black or African-American': 0.6361486736126506, 'More than one race': 0.5161290322580645, 'Native Hawaiian or other Pacific Islander': 0.646795827123696, 'White': 0.6708879442673279}\n",
      "\u001b[32m\u001b[1m# c-index=0.5853, mean=0.6373 std=0.0520\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 4: {'American Indian or Alaska Native': 0.6839430894308943, 'Asian': 0.6446978335233752, 'Black or African-American': 0.6424665632158427, 'More than one race': 0.5255704169944925, 'Native Hawaiian or other Pacific Islander': 0.6564828614008942, 'White': 0.6705140315661038}\n",
      "\n",
      "ENSEMBLE:\n",
      "\u001b[32m\u001b[1m# c-index=0.5826, mean=0.6374 std=0.0548\u001b[0m\n",
      "imbalanced test set evaluation metric: {'American Indian or Alaska Native': 0.6839430894308943, 'Asian': 0.6446978335233752, 'Black or African-American': 0.6424665632158427, 'More than one race': 0.5255704169944925, 'Native Hawaiian or other Pacific Islander': 0.6564828614008942, 'White': 0.6705140315661038}\n"
     ]
    }
   ],
   "source": [
    "ensemble_imbalanced_metric_dict, imbalanced_metric_dicts = evaluate_test_set(test, \n",
    "                                                                             \"xgb_model_downweight_majority\", skf, FEATURES, custom_score, dataset_name=\"imbalanced test set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_09fa9_row0_col0 {\n",
       "  background-color: #f10eff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row0_col1 {\n",
       "  background-color: #f708ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row0_col2 {\n",
       "  background-color: #e51aff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row0_col3 {\n",
       "  background-color: #ff00ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row0_col4 {\n",
       "  background-color: #f20dff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row0_col5 {\n",
       "  background-color: #f30cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row1_col0 {\n",
       "  background-color: #c33cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row1_col1 {\n",
       "  background-color: #c53aff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row1_col2 {\n",
       "  background-color: #bc43ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row1_col3 {\n",
       "  background-color: #c23dff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row1_col4, #T_09fa9_row2_col2 {\n",
       "  background-color: #be41ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row1_col5, #T_09fa9_row4_col3 {\n",
       "  background-color: #c13eff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row2_col0 {\n",
       "  background-color: #bf40ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row2_col1 {\n",
       "  background-color: #b748ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row2_col3 {\n",
       "  background-color: #b34cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row2_col4 {\n",
       "  background-color: #bb44ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row2_col5 {\n",
       "  background-color: #ba45ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row3_col0 {\n",
       "  background-color: #00ffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_09fa9_row3_col1 {\n",
       "  background-color: #34cbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_09fa9_row3_col2 {\n",
       "  background-color: #0ff0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_09fa9_row3_col3 {\n",
       "  background-color: #13ecff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_09fa9_row3_col4 {\n",
       "  background-color: #20dfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_09fa9_row3_col5 {\n",
       "  background-color: #18e7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_09fa9_row4_col0, #T_09fa9_row4_col5 {\n",
       "  background-color: #cc33ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row4_col1, #T_09fa9_row4_col4 {\n",
       "  background-color: #ce31ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row4_col2 {\n",
       "  background-color: #d629ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row5_col0, #T_09fa9_row5_col1, #T_09fa9_row5_col5 {\n",
       "  background-color: #e21dff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row5_col2 {\n",
       "  background-color: #e718ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row5_col3 {\n",
       "  background-color: #e11eff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09fa9_row5_col4 {\n",
       "  background-color: #e01fff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_09fa9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_09fa9_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_09fa9_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_09fa9_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_09fa9_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_09fa9_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_09fa9_level0_col5\" class=\"col_heading level0 col5\" >Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_09fa9_level0_row0\" class=\"row_heading level0 row0\" >American Indian or Alaska Native</th>\n",
       "      <td id=\"T_09fa9_row0_col0\" class=\"data row0 col0\" >0.6833</td>\n",
       "      <td id=\"T_09fa9_row0_col1\" class=\"data row0 col1\" >0.6877</td>\n",
       "      <td id=\"T_09fa9_row0_col2\" class=\"data row0 col2\" >0.6745</td>\n",
       "      <td id=\"T_09fa9_row0_col3\" class=\"data row0 col3\" >0.6941</td>\n",
       "      <td id=\"T_09fa9_row0_col4\" class=\"data row0 col4\" >0.6839</td>\n",
       "      <td id=\"T_09fa9_row0_col5\" class=\"data row0 col5\" >0.6847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09fa9_level0_row1\" class=\"row_heading level0 row1\" >Asian</th>\n",
       "      <td id=\"T_09fa9_row1_col0\" class=\"data row1 col0\" >0.6483</td>\n",
       "      <td id=\"T_09fa9_row1_col1\" class=\"data row1 col1\" >0.6502</td>\n",
       "      <td id=\"T_09fa9_row1_col2\" class=\"data row1 col2\" >0.6433</td>\n",
       "      <td id=\"T_09fa9_row1_col3\" class=\"data row1 col3\" >0.6481</td>\n",
       "      <td id=\"T_09fa9_row1_col4\" class=\"data row1 col4\" >0.6447</td>\n",
       "      <td id=\"T_09fa9_row1_col5\" class=\"data row1 col5\" >0.6469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09fa9_level0_row2\" class=\"row_heading level0 row2\" >Black or African-American</th>\n",
       "      <td id=\"T_09fa9_row2_col0\" class=\"data row2 col0\" >0.6459</td>\n",
       "      <td id=\"T_09fa9_row2_col1\" class=\"data row2 col1\" >0.6394</td>\n",
       "      <td id=\"T_09fa9_row2_col2\" class=\"data row2 col2\" >0.6444</td>\n",
       "      <td id=\"T_09fa9_row2_col3\" class=\"data row2 col3\" >0.6361</td>\n",
       "      <td id=\"T_09fa9_row2_col4\" class=\"data row2 col4\" >0.6425</td>\n",
       "      <td id=\"T_09fa9_row2_col5\" class=\"data row2 col5\" >0.6417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09fa9_level0_row3\" class=\"row_heading level0 row3\" >More than one race</th>\n",
       "      <td id=\"T_09fa9_row3_col0\" class=\"data row3 col0\" >0.5012</td>\n",
       "      <td id=\"T_09fa9_row3_col1\" class=\"data row3 col1\" >0.5405</td>\n",
       "      <td id=\"T_09fa9_row3_col2\" class=\"data row3 col2\" >0.5130</td>\n",
       "      <td id=\"T_09fa9_row3_col3\" class=\"data row3 col3\" >0.5161</td>\n",
       "      <td id=\"T_09fa9_row3_col4\" class=\"data row3 col4\" >0.5256</td>\n",
       "      <td id=\"T_09fa9_row3_col5\" class=\"data row3 col5\" >0.5193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09fa9_level0_row4\" class=\"row_heading level0 row4\" >Native Hawaiian or other Pacific Islander</th>\n",
       "      <td id=\"T_09fa9_row4_col0\" class=\"data row4 col0\" >0.6550</td>\n",
       "      <td id=\"T_09fa9_row4_col1\" class=\"data row4 col1\" >0.6565</td>\n",
       "      <td id=\"T_09fa9_row4_col2\" class=\"data row4 col2\" >0.6632</td>\n",
       "      <td id=\"T_09fa9_row4_col3\" class=\"data row4 col3\" >0.6468</td>\n",
       "      <td id=\"T_09fa9_row4_col4\" class=\"data row4 col4\" >0.6565</td>\n",
       "      <td id=\"T_09fa9_row4_col5\" class=\"data row4 col5\" >0.6556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09fa9_level0_row5\" class=\"row_heading level0 row5\" >White</th>\n",
       "      <td id=\"T_09fa9_row5_col0\" class=\"data row5 col0\" >0.6719</td>\n",
       "      <td id=\"T_09fa9_row5_col1\" class=\"data row5 col1\" >0.6716</td>\n",
       "      <td id=\"T_09fa9_row5_col2\" class=\"data row5 col2\" >0.6760</td>\n",
       "      <td id=\"T_09fa9_row5_col3\" class=\"data row5 col3\" >0.6709</td>\n",
       "      <td id=\"T_09fa9_row5_col4\" class=\"data row5 col4\" >0.6705</td>\n",
       "      <td id=\"T_09fa9_row5_col5\" class=\"data row5 col5\" >0.6722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09fa9_level0_foot0_row0\" class=\"foot0_row_heading level0 foot0_row0\" >mean</th>\n",
       "      <td id=\"T_09fa9_foot0_row0_col0\" class=\"foot0_data foot0_row0 col0\" >0.634</td>\n",
       "      <td id=\"T_09fa9_foot0_row0_col1\" class=\"foot0_data foot0_row0 col1\" >0.641</td>\n",
       "      <td id=\"T_09fa9_foot0_row0_col2\" class=\"foot0_data foot0_row0 col2\" >0.636</td>\n",
       "      <td id=\"T_09fa9_foot0_row0_col3\" class=\"foot0_data foot0_row0 col3\" >0.635</td>\n",
       "      <td id=\"T_09fa9_foot0_row0_col4\" class=\"foot0_data foot0_row0 col4\" >0.637</td>\n",
       "      <td id=\"T_09fa9_foot0_row0_col5\" class=\"foot0_data foot0_row0 col5\" >0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09fa9_level0_foot0_row1\" class=\"foot0_row_heading level0 foot0_row1\" >std</th>\n",
       "      <td id=\"T_09fa9_foot0_row1_col0\" class=\"foot0_data foot0_row1 col0\" >0.061</td>\n",
       "      <td id=\"T_09fa9_foot0_row1_col1\" class=\"foot0_data foot0_row1 col1\" >0.048</td>\n",
       "      <td id=\"T_09fa9_foot0_row1_col2\" class=\"foot0_data foot0_row1 col2\" >0.056</td>\n",
       "      <td id=\"T_09fa9_foot0_row1_col3\" class=\"foot0_data foot0_row1 col3\" >0.057</td>\n",
       "      <td id=\"T_09fa9_foot0_row1_col4\" class=\"foot0_data foot0_row1 col4\" >0.052</td>\n",
       "      <td id=\"T_09fa9_foot0_row1_col5\" class=\"foot0_data foot0_row1 col5\" >0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09fa9_level0_foot0_row2\" class=\"foot0_row_heading level0 foot0_row2\" >score</th>\n",
       "      <td id=\"T_09fa9_foot0_row2_col0\" class=\"foot0_data foot0_row2 col0\" >0.573</td>\n",
       "      <td id=\"T_09fa9_foot0_row2_col1\" class=\"foot0_data foot0_row2 col1\" >0.593</td>\n",
       "      <td id=\"T_09fa9_foot0_row2_col2\" class=\"foot0_data foot0_row2 col2\" >0.579</td>\n",
       "      <td id=\"T_09fa9_foot0_row2_col3\" class=\"foot0_data foot0_row2 col3\" >0.579</td>\n",
       "      <td id=\"T_09fa9_foot0_row2_col4\" class=\"foot0_data foot0_row2 col4\" >0.585</td>\n",
       "      <td id=\"T_09fa9_foot0_row2_col5\" class=\"foot0_data foot0_row2 col5\" >0.582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x358692a30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_overall(pd.DataFrame(imbalanced_metric_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race_group\n",
       "White                                        0.456954\n",
       "Black or African-American                    0.245033\n",
       "Asian                                        0.108798\n",
       "American Indian or Alaska Native             0.081362\n",
       "More than one race                           0.053926\n",
       "Native Hawaiian or other Pacific Islander    0.053926\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['race_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:53:37.820277Z",
     "iopub.status.busy": "2024-12-10T06:53:37.819499Z",
     "iopub.status.idle": "2024-12-10T06:53:37.824829Z",
     "shell.execute_reply": "2024-12-10T06:53:37.823859Z",
     "shell.execute_reply.started": "2024-12-10T06:53:37.820232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For inference:\n",
    "# model_path = f\"./xxx/xgb_model.bin\"\n",
    "# model = XGBRegressor()\n",
    "# model.load_model(model_path)\n",
    "# prediction = model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:55:23.498382Z",
     "iopub.status.busy": "2024-12-10T06:55:23.497743Z",
     "iopub.status.idle": "2024-12-10T07:01:01.257051Z",
     "shell.execute_reply": "2024-12-10T07:01:01.256322Z",
     "shell.execute_reply.started": "2024-12-10T06:55:23.49835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "    \n",
    "oof_lgb = train[['kfold','ID','efs','efs_time','label','race_group']].copy()\n",
    "oof_lgb['prediction'] = 0.0\n",
    "feature_importances_lgb = pd.DataFrame()\n",
    "feature_importances_lgb['feature'] = FEATURES\n",
    "metric_df = []\n",
    "\n",
    "for fold in range(skf.n_splits):\n",
    "    \n",
    "    x_train = train[train.kfold != fold].copy()\n",
    "    x_valid = train[train.kfold == fold].copy()\n",
    "\n",
    "    y_train = x_train['label']\n",
    "    y_valid = x_valid['label']\n",
    "    y_label = x_valid['efs']\n",
    "\n",
    "    x_train = x_train[FEATURES]\n",
    "    x_valid = x_valid[FEATURES]\n",
    "\n",
    "    ds_true = oof_lgb.loc[oof_lgb.kfold==fold, [\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy().reset_index(drop=True)\n",
    "    ds_pred = oof_lgb.loc[oof_lgb.kfold==fold, [\"ID\"]].copy().reset_index(drop=True)\n",
    "\n",
    "    lgb_params = {\n",
    "        'max_depth': 6,\n",
    "        'num_leaves': 40,\n",
    "        'learning_rate': 0.03,\n",
    "        'n_estimators': 10000,\n",
    "        'objective': 'l2',\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1,\n",
    "        'device': 'gpu',\n",
    "        'metric': 'None' # only show the custom metric\n",
    "    }\n",
    "    clf = LGBMRegressor(**lgb_params)\n",
    "    clf.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        categorical_feature=CAT_FEATURES,\n",
    "        eval_metric=CIndexMetric_LGB, # the custom metric\n",
    "        callbacks=[callback.log_evaluation(500), callback.early_stopping(100)]\n",
    "    )\n",
    "    feature_importances_lgb[f'fold_{fold + 1}'] = clf.feature_importances_\n",
    "\n",
    "    preds_valid = clf.predict(x_valid)\n",
    "    oof_lgb.loc[oof_lgb.kfold==fold, 'prediction'] = preds_valid\n",
    "\n",
    "    joblib.dump(clf, f\"lgb_model_{fold}.pkl\")\n",
    "\n",
    "    y_true = oof_lgb.loc[oof_lgb.kfold==fold, [\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy().reset_index(drop=True)\n",
    "    y_pred = oof_lgb.loc[oof_lgb.kfold==fold, [\"ID\",\"prediction\"]].copy().reset_index(drop=True)\n",
    "    m, metric_dict = custom_score(y_true, y_pred, \"ID\", print_info=True)\n",
    "    metric_df.append(metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T07:01:05.457732Z",
     "iopub.status.busy": "2024-12-10T07:01:05.457276Z",
     "iopub.status.idle": "2024-12-10T07:01:05.462006Z",
     "shell.execute_reply": "2024-12-10T07:01:05.461136Z",
     "shell.execute_reply.started": "2024-12-10T07:01:05.457681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For inference:\n",
    "# model_path = f\"./xxx/lgb_model.pkl\"\n",
    "# model = joblib.load(model_path)\n",
    "# prediction = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T07:01:07.800526Z",
     "iopub.status.busy": "2024-12-10T07:01:07.799836Z",
     "iopub.status.idle": "2024-12-10T07:01:08.123931Z",
     "shell.execute_reply": "2024-12-10T07:01:08.123106Z",
     "shell.execute_reply.started": "2024-12-10T07:01:07.800488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_true = oof_lgb[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy().reset_index(drop=True)\n",
    "y_pred = oof_lgb[[\"ID\",\"prediction\"]].copy().reset_index(drop=True)\n",
    "m, _ = custom_score(y_true, y_pred, \"ID\", print_info=True)\n",
    "print(f\"Overall official SCORE: {m:.5f}\")\n",
    "\n",
    "metric_df_ = pd.DataFrame(metric_df)\n",
    "display_overall(metric_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T07:01:19.336717Z",
     "iopub.status.busy": "2024-12-10T07:01:19.336365Z",
     "iopub.status.idle": "2024-12-10T07:01:19.65227Z",
     "shell.execute_reply": "2024-12-10T07:01:19.651589Z",
     "shell.execute_reply.started": "2024-12-10T07:01:19.336687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = 0.5*oof_xgb['prediction'].rank(pct=True) + 0.5*oof_lgb['prediction'].rank(pct=True)\n",
    "\n",
    "m, _ = custom_score(y_true, y_pred, \"ID\", print_info=True)\n",
    "print(f\"Overall official SCORE: {m:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "sourceId": 70942,
     "sourceType": "competition"
    },
    {
     "sourceId": 211253469,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 211322530,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 212249161,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
