{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:44:59.875459Z",
     "iopub.status.busy": "2024-12-10T06:44:59.874634Z",
     "iopub.status.idle": "2024-12-10T06:45:28.125023Z",
     "shell.execute_reply": "2024-12-10T06:45:28.123748Z",
     "shell.execute_reply.started": "2024-12-10T06:44:59.875387Z"
    },
    "trusted": true
   },
   "source": [
    "# Original notebook:\n",
    "https://www.kaggle.com/code/takanashihumbert/cibmtr-using-official-metric-in-tree-based-models/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:43.061047Z",
     "iopub.status.busy": "2024-12-10T06:45:43.060393Z",
     "iopub.status.idle": "2024-12-10T06:45:43.067555Z",
     "shell.execute_reply": "2024-12-10T06:45:43.066738Z",
     "shell.execute_reply.started": "2024-12-10T06:45:43.061012Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are using xgboost == 2.1.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, LabelEncoder\n",
    "import os, glob, math, gc, warnings, random, joblib\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool, CatBoostRegressor\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import xgboost as xgb\n",
    "print(\"we are using xgboost ==\", xgb.__version__)\n",
    "from lightgbm import LGBMRegressor, callback\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "import pdb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:48.24552Z",
     "iopub.status.busy": "2024-12-10T06:45:48.24517Z",
     "iopub.status.idle": "2024-12-10T06:45:48.25547Z",
     "shell.execute_reply": "2024-12-10T06:45:48.254582Z",
     "shell.execute_reply.started": "2024-12-10T06:45:48.245489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def custom_score(solution, submission, row_id_column_name, prediction_label='prediction', print_info=True):\n",
    "    \n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "    \n",
    "    event_label = 'efs'\n",
    "    interval_label = 'efs_time'\n",
    "    \n",
    "    for col in submission.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(submission[col]):\n",
    "            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n",
    "    # Merging solution and submission dfs on ID\n",
    "    merged_df = pd.concat([solution, submission], axis=1)\n",
    "    merged_df.reset_index(inplace=True)\n",
    "    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n",
    "    metric_dict = {}\n",
    "    for race in sorted(merged_df_race_dict.keys()):\n",
    "        # Retrieving values from y_test based on index\n",
    "        indices = sorted(merged_df_race_dict[race])\n",
    "        merged_df_race = merged_df.iloc[indices]\n",
    "        # Calculate the concordance index\n",
    "        c_index_race = concordance_index(\n",
    "                        merged_df_race[interval_label],\n",
    "                        -merged_df_race[prediction_label],\n",
    "                        merged_df_race[event_label])\n",
    "\n",
    "        metric_dict[race] = c_index_race\n",
    "\n",
    "    race_c_index = list(metric_dict.values())\n",
    "    c_score = float(np.mean(race_c_index) - np.std(race_c_index))\n",
    "    if print_info:\n",
    "        print(f\"{Fore.GREEN}{Style.BRIGHT}# c-index={c_score:.4f}, mean={np.mean(race_c_index):.4f} std={np.std(race_c_index):.4f}{Style.RESET_ALL}\")\n",
    "    \n",
    "    return c_score, metric_dict\n",
    "\n",
    "\n",
    "def display_overall(df):\n",
    "    \n",
    "    race_groups = [\n",
    "        'American Indian or Alaska Native', 'Asian',\n",
    "       'Black or African-American', 'More than one race',\n",
    "       'Native Hawaiian or other Pacific Islander', 'White'\n",
    "    ]\n",
    "    df['mean'] = df[race_groups].mean(axis=1)\n",
    "    df['std'] = np.std(df[race_groups], axis=1)\n",
    "    df['score'] = df['mean'] - df['std']\n",
    "    df = df.T\n",
    "    df['Overall'] = df.mean(axis=1)\n",
    "    temp = df.drop(index=['std']).values\n",
    "    display(df\n",
    "            .iloc[:len(race_groups)]\n",
    "            .style\n",
    "            .format(precision=4)\n",
    "            .background_gradient(axis=None, vmin=temp.min(), vmax=temp.max(), cmap=\"cool\")\n",
    "            .concat(df.iloc[len(race_groups):].style.format(precision=3))\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:48.958627Z",
     "iopub.status.busy": "2024-12-10T06:45:48.957939Z",
     "iopub.status.idle": "2024-12-10T06:45:49.287763Z",
     "shell.execute_reply": "2024-12-10T06:45:49.28684Z",
     "shell.execute_reply.started": "2024-12-10T06:45:48.95859Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (1057, 60)\n",
      "Balanced Test shape: (2880, 60)\n",
      "Train shape: (25920, 60)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"../preprocessed_data/custom_test_0.1_imbalanced.csv\")\n",
    "print(\"Test shape:\", test.shape )\n",
    "\n",
    "test_balanced = pd.read_csv(\"../preprocessed_data/custom_test_0.1_balanced.csv\")\n",
    "print(\"Balanced Test shape:\", test_balanced.shape )\n",
    "\n",
    "train = pd.read_csv(\"../preprocessed_data/custom_train_0.9_balanced.csv\")\n",
    "print(\"Train shape:\",train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:49.936711Z",
     "iopub.status.busy": "2024-12-10T06:45:49.935964Z",
     "iopub.status.idle": "2024-12-10T06:45:49.941283Z",
     "shell.execute_reply": "2024-12-10T06:45:49.940427Z",
     "shell.execute_reply.started": "2024-12-10T06:45:49.936677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def transform_survival_probability(df, time_col='efs_time', event_col='efs'):\n",
    "    \"\"\"\n",
    "    Transform using survival probability estimates\n",
    "    \"\"\"\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(df[time_col], df[event_col])\n",
    "    y = kmf.survival_function_at_times(df[time_col]).values\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's substract 0.1 instead of 0.2 from the Kaplan Meier survival scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:50.340453Z",
     "iopub.status.busy": "2024-12-10T06:45:50.340144Z",
     "iopub.status.idle": "2024-12-10T06:45:50.697919Z",
     "shell.execute_reply": "2024-12-10T06:45:50.69707Z",
     "shell.execute_reply.started": "2024-12-10T06:45:50.340393Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SUBTRACT_KP_SCORE = 0.15\n",
    "\n",
    "train[\"label\"] = transform_survival_probability(train, time_col='efs_time', event_col='efs')\n",
    "train.loc[train['efs']==0, 'label'] -= SUBTRACT_KP_SCORE # or -0.1 according to other notebook\n",
    "\n",
    "test['label'] = transform_survival_probability(test, time_col='efs_time', event_col='efs')\n",
    "test.loc[test['efs']==0, 'label'] -= SUBTRACT_KP_SCORE # or -0.1 according to other notebook\n",
    "test_balanced['label'] = transform_survival_probability(test_balanced, time_col='efs_time', event_col='efs')\n",
    "test_balanced.loc[test_balanced['efs']==0, 'label'] -= SUBTRACT_KP_SCORE # or -0.1 according to other notebook\n",
    "\n",
    "sns.histplot(data=train, x='label', hue='efs', element='step', common_norm=False)\n",
    "plt.legend(title='efs')\n",
    "plt.title('Distribution of Target by EFS')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's convert year_hct to year_hct_from_baseline to avoid a big difference in scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_YEAR = train['year_hct'].min() # 2008\n",
    "train['year_hct_relative'] = train['year_hct'] - MIN_YEAR\n",
    "train.drop(columns=['year_hct'], inplace=True)\n",
    "\n",
    "test['year_hct_relative'] = test['year_hct'] - MIN_YEAR\n",
    "test.drop(columns=['year_hct'], inplace=True)   \n",
    "\n",
    "test_balanced['year_hct_relative'] = test_balanced['year_hct'] - MIN_YEAR   \n",
    "test_balanced.drop(columns=['year_hct'], inplace=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:52.769417Z",
     "iopub.status.busy": "2024-12-10T06:45:52.769048Z",
     "iopub.status.idle": "2024-12-10T06:45:52.774899Z",
     "shell.execute_reply": "2024-12-10T06:45:52.773877Z",
     "shell.execute_reply.started": "2024-12-10T06:45:52.769363Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 FEATURES: ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'hla_match_c_high', 'hla_high_res_8', 'tbi_status', 'arrhythmia', 'hla_low_res_6', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'hla_high_res_6', 'cmv_status', 'hla_high_res_10', 'hla_match_dqb1_high', 'tce_imm_match', 'hla_nmdp_6', 'hla_match_c_low', 'rituximab', 'hla_match_drb1_low', 'hla_match_dqb1_low', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hla_match_a_high', 'hepatic_severe', 'donor_age', 'prior_tumor', 'hla_match_b_low', 'peptic_ulcer', 'age_at_hct', 'hla_match_a_low', 'gvhd_proph', 'rheum_issue', 'sex_match', 'hla_match_b_high', 'race_group', 'comorbidity_score', 'karnofsky_score', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'hla_low_res_8', 'cardiac', 'hla_match_drb1_high', 'pulm_moderate', 'hla_low_res_10', 'year_hct_relative']\n"
     ]
    }
   ],
   "source": [
    "RMV = [\"ID\",\"efs\",\"efs_time\",\"label\",'y','kfold']\n",
    "FEATURES = [c for c in train.columns if not c in RMV]\n",
    "print(f\"There are {len(FEATURES)} FEATURES: {FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:53.095326Z",
     "iopub.status.busy": "2024-12-10T06:45:53.095056Z",
     "iopub.status.idle": "2024-12-10T06:45:53.863499Z",
     "shell.execute_reply": "2024-12-10T06:45:53.862823Z",
     "shell.execute_reply.started": "2024-12-10T06:45:53.095299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CAT_FEATURES = []\n",
    "for c in FEATURES:\n",
    "    if train[c].dtype==\"object\":\n",
    "        CAT_FEATURES.append(c)\n",
    "        train[c] = train[c].fillna(\"NAN\")\n",
    "        test[c] = test[c].fillna(\"NAN\")\n",
    "        test_balanced[c] = test_balanced[c].fillna(\"NAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:53.864972Z",
     "iopub.status.busy": "2024-12-10T06:45:53.864713Z",
     "iopub.status.idle": "2024-12-10T06:45:53.955581Z",
     "shell.execute_reply": "2024-12-10T06:45:53.954793Z",
     "shell.execute_reply.started": "2024-12-10T06:45:53.864946Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CATEGORICAL FEATURES: dri_score, psych_disturb, cyto_score, diabetes, tbi_status, arrhythmia, graft_type, vent_hist, renal_issue, pulm_severe, prim_disease_hct, cmv_status, tce_imm_match, rituximab, prod_type, cyto_score_detail, conditioning_intensity, ethnicity, obesity, mrd_hct, in_vivo_tcd, tce_match, hepatic_severe, prior_tumor, peptic_ulcer, gvhd_proph, rheum_issue, sex_match, race_group, hepatic_mild, tce_div_match, donor_related, melphalan_dose, cardiac, pulm_moderate, "
     ]
    }
   ],
   "source": [
    "combined = pd.concat([train, test, test_balanced], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"The CATEGORICAL FEATURES: \", end=\"\")\n",
    "for c in FEATURES:\n",
    "    if c in CAT_FEATURES:\n",
    "        print(f\"{c}, \", end=\"\")\n",
    "        combined[c] = combined[c].astype(\"category\")\n",
    "    else:\n",
    "        if combined[c].dtype == \"float64\":\n",
    "            combined[c] = combined[c].astype(\"float32\")\n",
    "        if combined[c].dtype == \"int64\":\n",
    "            combined[c] = combined[c].astype(\"int32\")\n",
    "\n",
    "train = combined.iloc[:len(train)].copy()\n",
    "test = combined.iloc[len(train):len(train) + len(test)].reset_index(drop=True).copy()\n",
    "test_balanced = combined.iloc[len(train) + len(test):].reset_index(drop=True).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:55.924938Z",
     "iopub.status.busy": "2024-12-10T06:45:55.924108Z",
     "iopub.status.idle": "2024-12-10T06:45:55.975816Z",
     "shell.execute_reply": "2024-12-10T06:45:55.975216Z",
     "shell.execute_reply.started": "2024-12-10T06:45:55.924902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "folds = 5\n",
    "train['kfold'] = -1  \n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "groups = train['efs'].astype(str)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X=train, y=groups)):\n",
    "    train.loc[val_idx, 'kfold'] = fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:57.061938Z",
     "iopub.status.busy": "2024-12-10T06:45:57.061563Z",
     "iopub.status.idle": "2024-12-10T06:45:57.067525Z",
     "shell.execute_reply": "2024-12-10T06:45:57.0666Z",
     "shell.execute_reply.started": "2024-12-10T06:45:57.061902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def CIndexMetric_XGB(y_true, y_pred):\n",
    "    ds_pred[\"prediction\"] = y_pred\n",
    "    cindex_score, _ = custom_score(ds_true.copy(), ds_pred.copy(), \"ID\", print_info=False)\n",
    "    return -cindex_score\n",
    "\n",
    "def CIndexMetric_LGB(y_true, y_pred):\n",
    "    ds_pred[\"prediction\"] = y_pred\n",
    "    cindex_score, _ = custom_score(ds_true.copy(), ds_pred.copy(), \"ID\", print_info=False)\n",
    "    return ('C-Index', cindex_score, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_equity_loss(race_groups):\n",
    "    \"\"\"\n",
    "    Returns a custom objective function for XGBoost that applies group-level \n",
    "    weighting to the standard squared error loss. This function assumes a loss \n",
    "    of 0.5*(pred - y)^2 and scales the gradient and Hessian for each sample i \n",
    "    in group g by 1/(n_g * num_groups).\n",
    "\n",
    "    Parameters:\n",
    "      race_groups: 1D numpy array of race group labels in the exact order \n",
    "                   corresponding to the training data that XGBoost sees.\n",
    "                   \n",
    "    Returns:\n",
    "      A callable function (preds, dtrain) -> (grad, hess)\n",
    "    \"\"\"\n",
    "    # Get the unique group labels and count them.\n",
    "    unique_groups = np.unique(race_groups)\n",
    "    num_groups = len(unique_groups)\n",
    "    # Compute the count of samples in each group.\n",
    "    group_counts = {g: np.sum(race_groups == g) for g in unique_groups}\n",
    "    # For each sample, compute the scaling factor = 1/(n_g * num_groups)\n",
    "    factors = np.array([1.0 / (group_counts[r] * num_groups) for r in race_groups])\n",
    "    # pdb.set_trace()\n",
    "    def loss(preds, dtrain):\n",
    "        pdb.set_trace()\n",
    "        # dtrain.get_label() returns the labels in the same order as the training data.\n",
    "        y = dtrain.get_label()\n",
    "        # Compute gradient and hessian.\n",
    "        grad = factors * (preds - y)\n",
    "        hess = factors  # constant for each sample.\n",
    "        return grad, hess\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_equity_loss(race_groups):\n",
    "    \"\"\"\n",
    "    Vectorized custom objective function for XGBoost that approximates a \n",
    "    stratified c-index using a pairwise logistic loss computed within each race group.\n",
    "\n",
    "    Parameters:\n",
    "        race_groups (np.array): 1D array of race_group values corresponding to \n",
    "                                the training samples.\n",
    "    \"\"\"\n",
    "    unique_groups, group_indices = np.unique(race_groups, return_inverse=True)\n",
    "\n",
    "    def loss_fn(preds, dtrain):\n",
    "        labels = dtrain.get_label()\n",
    "        grad = np.zeros_like(preds)\n",
    "        hess = np.zeros_like(preds)\n",
    "        alpha = 1.0  # Scaling factor (can be tuned)\n",
    "\n",
    "        # Process each race group efficiently\n",
    "        for group in np.unique(group_indices):\n",
    "            indices = np.where(group_indices == group)[0]\n",
    "            if len(indices) < 2:\n",
    "                continue  # Skip small groups\n",
    "            \n",
    "            group_preds = preds[indices][:, np.newaxis]  # Shape (N, 1)\n",
    "            group_labels = labels[indices][:, np.newaxis]  # Shape (N, 1)\n",
    "\n",
    "            # Compute all pairwise differences at once\n",
    "            label_diff = group_labels - group_labels.T  # Shape (N, N)\n",
    "            pred_diff = group_preds - group_preds.T  # Shape (N, N)\n",
    "            \n",
    "            # Only keep comparisons where labels differ\n",
    "            valid_pairs = label_diff != 0\n",
    "            margin = alpha * label_diff * pred_diff\n",
    "            exp_neg_margin = np.exp(-margin)\n",
    "            sigma = exp_neg_margin / (1.0 + exp_neg_margin)\n",
    "            \n",
    "            # Compute gradients and Hessians in a vectorized manner\n",
    "            pair_grad = -alpha * label_diff * sigma\n",
    "            pair_hess = alpha**2 * (label_diff**2) * sigma * (1 - sigma)\n",
    "\n",
    "            # Sum contributions for each sample\n",
    "            grad[indices] = np.sum(pair_grad * valid_pairs, axis=1)\n",
    "            hess[indices] = np.sum(pair_hess * valid_pairs, axis=1)\n",
    "\n",
    "        return grad, hess\n",
    "\n",
    "    return loss_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost with custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:45:59.406701Z",
     "iopub.status.busy": "2024-12-10T06:45:59.406346Z",
     "iopub.status.idle": "2024-12-10T06:53:30.590393Z",
     "shell.execute_reply": "2024-12-10T06:53:30.589586Z",
     "shell.execute_reply.started": "2024-12-10T06:45:59.406671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-auc:0.57293\n",
      "[500]\tvalidation-auc:0.62155\n",
      "[1000]\tvalidation-auc:0.62569\n",
      "[1465]\tvalidation-auc:0.62647\n",
      "\u001b[32m\u001b[1m# c-index=0.6728, mean=0.6871 std=0.0143\u001b[0m\n",
      "[0]\tvalidation-auc:0.57633\n",
      "[500]\tvalidation-auc:0.62144\n",
      "[1000]\tvalidation-auc:0.62485\n",
      "[1500]\tvalidation-auc:0.62571\n",
      "[1811]\tvalidation-auc:0.62558\n",
      "\u001b[32m\u001b[1m# c-index=0.6741, mean=0.6902 std=0.0161\u001b[0m\n",
      "[0]\tvalidation-auc:0.57554\n",
      "[500]\tvalidation-auc:0.62042\n",
      "[1000]\tvalidation-auc:0.62177\n",
      "[1287]\tvalidation-auc:0.62186\n",
      "\u001b[32m\u001b[1m# c-index=0.6772, mean=0.6833 std=0.0061\u001b[0m\n",
      "[0]\tvalidation-auc:0.57299\n",
      "[500]\tvalidation-auc:0.61747\n",
      "[1000]\tvalidation-auc:0.61991\n",
      "[1424]\tvalidation-auc:0.62017\n",
      "\u001b[32m\u001b[1m# c-index=0.6682, mean=0.6814 std=0.0132\u001b[0m\n",
      "[0]\tvalidation-auc:0.57284\n",
      "[500]\tvalidation-auc:0.62182\n",
      "[1000]\tvalidation-auc:0.62410\n",
      "[1491]\tvalidation-auc:0.62451\n",
      "\u001b[32m\u001b[1m# c-index=0.6768, mean=0.6868 std=0.0101\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Prepare the out-of-fold DataFrame to store predictions and additional metadata.\n",
    "oof_xgb = train[['kfold', 'ID', 'efs', 'efs_time', 'label', 'race_group']].copy()\n",
    "oof_xgb['prediction'] = 0.0\n",
    "feature_importances_xgb = pd.DataFrame({'feature': FEATURES})\n",
    "metric_df = []\n",
    "\n",
    "for fold in range(skf.n_splits):\n",
    "    # Split into training and validation sets.\n",
    "    x_train_full = train[train.kfold != fold].copy()\n",
    "    x_valid_full = train[train.kfold == fold].copy()\n",
    "    \n",
    "    y_train = x_train_full['label'].values\n",
    "    y_valid = x_valid_full['label'].values\n",
    "    \n",
    "    # Extract race group info for the training set\n",
    "    race_groups_train = x_train_full['race_group'].values\n",
    "\n",
    "    # Convert training and validation data into DMatrix format\n",
    "    dtrain = xgb.DMatrix(x_train_full[FEATURES], label=y_train, enable_categorical=True)\n",
    "    dvalid = xgb.DMatrix(x_valid_full[FEATURES], label=y_valid, enable_categorical=True)\n",
    "\n",
    "    # Create the custom objective function\n",
    "    custom_obj = custom_equity_loss(race_groups_train)\n",
    "\n",
    "    # Define XGBoost parameters (excluding objective, since it's custom)\n",
    "    # Define XGBoost parameters (excluding objective, since it's custom)\n",
    "    params = {\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"max_depth\": 3,\n",
    "        \"colsample_bytree\": 0.5, \n",
    "        \"subsample\": 0.8, \n",
    "        \"learning_rate\": 0.03,\n",
    "        \"min_child_weight\": 5,\n",
    "        \"eval_metric\": \"auc\",  # Just to monitor performance\n",
    "        \"disable_default_eval_metric\": True\n",
    "    }\n",
    "\n",
    "    # Train the model using XGBoost's native API (not XGBRegressor)\n",
    "    clf = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=10000,\n",
    "        evals=[(dvalid, \"validation\")],\n",
    "        obj=custom_obj,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=500\n",
    "    )\n",
    "\n",
    "    # Store feature importance\n",
    "    feature_importances_xgb[f'fold_{fold + 1}'] = clf.get_score()\n",
    "\n",
    "    # Predict on validation fold and store predictions\n",
    "    preds_valid = clf.predict(dvalid)\n",
    "    # pdb.set_trace()\n",
    "    oof_xgb.loc[oof_xgb.kfold == fold, 'prediction'] = preds_valid\n",
    "\n",
    "    # Save model\n",
    "    clf.save_model(f\"xgb/xgb_model_custom_loss_{fold}.bin\")\n",
    "\n",
    "    # Evaluate custom metric\n",
    "    y_true = oof_xgb.loc[oof_xgb.kfold == fold, [\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy().reset_index(drop=True)\n",
    "    y_pred = oof_xgb.loc[oof_xgb.kfold == fold, [\"ID\", \"prediction\"]].copy().reset_index(drop=True)\n",
    "    m, metric_dict = custom_score(y_true, y_pred, \"ID\", print_info=True)\n",
    "    metric_df.append(metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_test_set(test_set, model_prefix, skf, FEATURES, custom_score, dataset_name=\"test set\"):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given test set (imbalanced or balanced).\n",
    "    \n",
    "    Parameters:\n",
    "        test_set (pd.DataFrame): The test set to evaluate.\n",
    "        model_prefix (str): Prefix for the saved model filenames.\n",
    "        skf (StratifiedKFold): Cross-validation object to determine the number of folds.\n",
    "        FEATURES (list): List of feature columns.\n",
    "        custom_score (function): Function to compute custom evaluation metric.\n",
    "        dataset_name (str): Name of the dataset for logging purposes.\n",
    "    \n",
    "    Returns:\n",
    "        None (prints evaluation results)\n",
    "    \"\"\"\n",
    "    print(f\"Evaluating on {dataset_name}...\")\n",
    "\n",
    "    # Ensure the test set has the required feature columns\n",
    "    if not set(FEATURES).issubset(test_set.columns):\n",
    "        raise ValueError(f\"{dataset_name} does not have all required feature columns.\")\n",
    "\n",
    "    # Initialize an array to accumulate predictions from each fold\n",
    "    test_predictions = np.zeros(len(test_set))\n",
    "\n",
    "    # Initialize a dictionary to store the evaluation metric for each fold\n",
    "    metric_df = []\n",
    "\n",
    "    # Loop over folds, load each saved model, and predict on the test set\n",
    "    for fold in range(skf.n_splits):\n",
    "        model_filename = f\"xgb/{model_prefix}_{fold}.bin\"\n",
    "        clf = XGBRegressor()  # We only use this to load the saved booster\n",
    "        clf.load_model(model_filename)\n",
    "        fold_pred = clf.predict(test_set[FEATURES])\n",
    "        test_set[f'prediction_{fold}'] = fold_pred\n",
    "\n",
    "        # If labels exist, compute the custom metric for this fold\n",
    "        if \"label\" in test_set.columns:\n",
    "            y_true_test = test_set[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy().reset_index(drop=True)\n",
    "            y_pred_test = test_set[[\"ID\", f\"prediction_{fold}\"]].copy().reset_index(drop=True)\n",
    "            m, metric_dict = custom_score(y_true_test, y_pred_test, \"ID\", print_info=True, prediction_label=f\"prediction_{fold}\")\n",
    "            print(f\"{dataset_name} evaluation metric for fold {fold}:\", metric_dict)\n",
    "            metric_df.append(metric_dict)\n",
    "\n",
    "        test_predictions += fold_pred\n",
    "\n",
    "    # Average the predictions across folds\n",
    "    test_predictions /= skf.n_splits\n",
    "    test_set['ensemble_prediction'] = test_predictions\n",
    "\n",
    "    print('\\nENSEMBLE:')\n",
    "    # If labels exist, compute the custom metric for an ensemble\n",
    "    if \"label\" in test_set.columns:\n",
    "        y_true_test = test_set[[\"ID\", \"efs\", \"efs_time\", \"race_group\"]].copy().reset_index(drop=True)\n",
    "        y_pred_test = test_set[[\"ID\", \"ensemble_prediction\"]].copy().reset_index(drop=True)\n",
    "        m, ensemble_metric_dict = custom_score(y_true_test, y_pred_test, \"ID\", print_info=True, prediction_label=\"ensemble_prediction\")\n",
    "        print(f\"{dataset_name} evaluation metric:\", metric_dict)\n",
    "    else:\n",
    "        print(f\"{dataset_name} predictions computed. No labels available for evaluation.\")\n",
    "    return ensemble_metric_dict, metric_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on full test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on balanced test set...\n",
      "\u001b[32m\u001b[1m# c-index=0.6550, mean=0.6679 std=0.0129\u001b[0m\n",
      "balanced test set evaluation metric for fold 0: {'American Indian or Alaska Native': 0.6914655840897688, 'Asian': 0.6713611320797233, 'Black or African-American': 0.6540248502802583, 'More than one race': 0.6633042751511915, 'Native Hawaiian or other Pacific Islander': 0.6540936985481215, 'White': 0.673406935096627}\n",
      "\u001b[32m\u001b[1m# c-index=0.6566, mean=0.6707 std=0.0140\u001b[0m\n",
      "balanced test set evaluation metric for fold 1: {'American Indian or Alaska Native': 0.6962892852255622, 'Asian': 0.6724990704958482, 'Black or African-American': 0.6546109417957844, 'More than one race': 0.6690733496616328, 'Native Hawaiian or other Pacific Islander': 0.6553947474468355, 'White': 0.6762309599716614}\n",
      "\u001b[32m\u001b[1m# c-index=0.6578, mean=0.6698 std=0.0120\u001b[0m\n",
      "balanced test set evaluation metric for fold 2: {'American Indian or Alaska Native': 0.6902682114674087, 'Asian': 0.6697161913989883, 'Black or African-American': 0.6539715692333923, 'More than one race': 0.668388489709689, 'Native Hawaiian or other Pacific Islander': 0.6586646402542227, 'White': 0.6780021253985122}\n",
      "\u001b[32m\u001b[1m# c-index=0.6568, mean=0.6693 std=0.0125\u001b[0m\n",
      "balanced test set evaluation metric for fold 3: {'American Indian or Alaska Native': 0.6905304930894495, 'Asian': 0.6716428000045067, 'Black or African-American': 0.651211611005733, 'More than one race': 0.6644186235475745, 'Native Hawaiian or other Pacific Islander': 0.6607831623547834, 'White': 0.6772444601881371}\n",
      "\u001b[32m\u001b[1m# c-index=0.6564, mean=0.6704 std=0.0140\u001b[0m\n",
      "balanced test set evaluation metric for fold 4: {'American Indian or Alaska Native': 0.6965287597500343, 'Asian': 0.6694457901911962, 'Black or African-American': 0.6562839666673771, 'More than one race': 0.6724047870549861, 'Native Hawaiian or other Pacific Islander': 0.6538864518208928, 'White': 0.6738300468374857}\n",
      "\n",
      "ENSEMBLE:\n",
      "\u001b[32m\u001b[1m# c-index=0.6588, mean=0.6717 std=0.0130\u001b[0m\n",
      "balanced test set evaluation metric: {'American Indian or Alaska Native': 0.6965287597500343, 'Asian': 0.6694457901911962, 'Black or African-American': 0.6562839666673771, 'More than one race': 0.6724047870549861, 'Native Hawaiian or other Pacific Islander': 0.6538864518208928, 'White': 0.6738300468374857}\n"
     ]
    }
   ],
   "source": [
    "ensemble_balanced_metric_dict, balanced_metric_dicts = evaluate_test_set(test_balanced, \n",
    "                                                                         \"xgb_model_custom_loss\", skf, FEATURES, custom_score, dataset_name=\"balanced test set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1ad14_row0_col0 {\n",
       "  background-color: #e31cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row0_col1 {\n",
       "  background-color: #fe01ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row0_col2 {\n",
       "  background-color: #dc23ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row0_col3 {\n",
       "  background-color: #de21ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row0_col4 {\n",
       "  background-color: #ff00ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row0_col5 {\n",
       "  background-color: #ec13ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row1_col0 {\n",
       "  background-color: #718eff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row1_col1 {\n",
       "  background-color: #7887ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row1_col2 {\n",
       "  background-color: #6897ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row1_col3 {\n",
       "  background-color: #738cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row1_col4 {\n",
       "  background-color: #6798ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row1_col5 {\n",
       "  background-color: #6f90ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row2_col0, #T_1ad14_row2_col2, #T_1ad14_row2_col5, #T_1ad14_row4_col4 {\n",
       "  background-color: #0ff0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1ad14_row2_col1 {\n",
       "  background-color: #13ecff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1ad14_row2_col3 {\n",
       "  background-color: #00ffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1ad14_row2_col4 {\n",
       "  background-color: #1ce3ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1ad14_row3_col0 {\n",
       "  background-color: #44bbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1ad14_row3_col1 {\n",
       "  background-color: #649bff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row3_col2 {\n",
       "  background-color: #619eff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row3_col3 {\n",
       "  background-color: #4ab5ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1ad14_row3_col4 {\n",
       "  background-color: #7788ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row3_col5 {\n",
       "  background-color: #5ca3ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row4_col0 {\n",
       "  background-color: #10efff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1ad14_row4_col1 {\n",
       "  background-color: #17e8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1ad14_row4_col2 {\n",
       "  background-color: #2ad5ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1ad14_row4_col3 {\n",
       "  background-color: #36c9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1ad14_row4_col5 {\n",
       "  background-color: #1ee1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1ad14_row5_col0 {\n",
       "  background-color: #7d82ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row5_col1 {\n",
       "  background-color: #8d72ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row5_col2 {\n",
       "  background-color: #9768ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row5_col3 {\n",
       "  background-color: #936cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row5_col4 {\n",
       "  background-color: #7f80ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1ad14_row5_col5 {\n",
       "  background-color: #8a75ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1ad14\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1ad14_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_1ad14_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_1ad14_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_1ad14_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_1ad14_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_1ad14_level0_col5\" class=\"col_heading level0 col5\" >Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1ad14_level0_row0\" class=\"row_heading level0 row0\" >American Indian or Alaska Native</th>\n",
       "      <td id=\"T_1ad14_row0_col0\" class=\"data row0 col0\" >0.6915</td>\n",
       "      <td id=\"T_1ad14_row0_col1\" class=\"data row0 col1\" >0.6963</td>\n",
       "      <td id=\"T_1ad14_row0_col2\" class=\"data row0 col2\" >0.6903</td>\n",
       "      <td id=\"T_1ad14_row0_col3\" class=\"data row0 col3\" >0.6905</td>\n",
       "      <td id=\"T_1ad14_row0_col4\" class=\"data row0 col4\" >0.6965</td>\n",
       "      <td id=\"T_1ad14_row0_col5\" class=\"data row0 col5\" >0.6930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ad14_level0_row1\" class=\"row_heading level0 row1\" >Asian</th>\n",
       "      <td id=\"T_1ad14_row1_col0\" class=\"data row1 col0\" >0.6714</td>\n",
       "      <td id=\"T_1ad14_row1_col1\" class=\"data row1 col1\" >0.6725</td>\n",
       "      <td id=\"T_1ad14_row1_col2\" class=\"data row1 col2\" >0.6697</td>\n",
       "      <td id=\"T_1ad14_row1_col3\" class=\"data row1 col3\" >0.6716</td>\n",
       "      <td id=\"T_1ad14_row1_col4\" class=\"data row1 col4\" >0.6694</td>\n",
       "      <td id=\"T_1ad14_row1_col5\" class=\"data row1 col5\" >0.6709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ad14_level0_row2\" class=\"row_heading level0 row2\" >Black or African-American</th>\n",
       "      <td id=\"T_1ad14_row2_col0\" class=\"data row2 col0\" >0.6540</td>\n",
       "      <td id=\"T_1ad14_row2_col1\" class=\"data row2 col1\" >0.6546</td>\n",
       "      <td id=\"T_1ad14_row2_col2\" class=\"data row2 col2\" >0.6540</td>\n",
       "      <td id=\"T_1ad14_row2_col3\" class=\"data row2 col3\" >0.6512</td>\n",
       "      <td id=\"T_1ad14_row2_col4\" class=\"data row2 col4\" >0.6563</td>\n",
       "      <td id=\"T_1ad14_row2_col5\" class=\"data row2 col5\" >0.6540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ad14_level0_row3\" class=\"row_heading level0 row3\" >More than one race</th>\n",
       "      <td id=\"T_1ad14_row3_col0\" class=\"data row3 col0\" >0.6633</td>\n",
       "      <td id=\"T_1ad14_row3_col1\" class=\"data row3 col1\" >0.6691</td>\n",
       "      <td id=\"T_1ad14_row3_col2\" class=\"data row3 col2\" >0.6684</td>\n",
       "      <td id=\"T_1ad14_row3_col3\" class=\"data row3 col3\" >0.6644</td>\n",
       "      <td id=\"T_1ad14_row3_col4\" class=\"data row3 col4\" >0.6724</td>\n",
       "      <td id=\"T_1ad14_row3_col5\" class=\"data row3 col5\" >0.6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ad14_level0_row4\" class=\"row_heading level0 row4\" >Native Hawaiian or other Pacific Islander</th>\n",
       "      <td id=\"T_1ad14_row4_col0\" class=\"data row4 col0\" >0.6541</td>\n",
       "      <td id=\"T_1ad14_row4_col1\" class=\"data row4 col1\" >0.6554</td>\n",
       "      <td id=\"T_1ad14_row4_col2\" class=\"data row4 col2\" >0.6587</td>\n",
       "      <td id=\"T_1ad14_row4_col3\" class=\"data row4 col3\" >0.6608</td>\n",
       "      <td id=\"T_1ad14_row4_col4\" class=\"data row4 col4\" >0.6539</td>\n",
       "      <td id=\"T_1ad14_row4_col5\" class=\"data row4 col5\" >0.6566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ad14_level0_row5\" class=\"row_heading level0 row5\" >White</th>\n",
       "      <td id=\"T_1ad14_row5_col0\" class=\"data row5 col0\" >0.6734</td>\n",
       "      <td id=\"T_1ad14_row5_col1\" class=\"data row5 col1\" >0.6762</td>\n",
       "      <td id=\"T_1ad14_row5_col2\" class=\"data row5 col2\" >0.6780</td>\n",
       "      <td id=\"T_1ad14_row5_col3\" class=\"data row5 col3\" >0.6772</td>\n",
       "      <td id=\"T_1ad14_row5_col4\" class=\"data row5 col4\" >0.6738</td>\n",
       "      <td id=\"T_1ad14_row5_col5\" class=\"data row5 col5\" >0.6757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ad14_level0_foot0_row0\" class=\"foot0_row_heading level0 foot0_row0\" >mean</th>\n",
       "      <td id=\"T_1ad14_foot0_row0_col0\" class=\"foot0_data foot0_row0 col0\" >0.668</td>\n",
       "      <td id=\"T_1ad14_foot0_row0_col1\" class=\"foot0_data foot0_row0 col1\" >0.671</td>\n",
       "      <td id=\"T_1ad14_foot0_row0_col2\" class=\"foot0_data foot0_row0 col2\" >0.670</td>\n",
       "      <td id=\"T_1ad14_foot0_row0_col3\" class=\"foot0_data foot0_row0 col3\" >0.669</td>\n",
       "      <td id=\"T_1ad14_foot0_row0_col4\" class=\"foot0_data foot0_row0 col4\" >0.670</td>\n",
       "      <td id=\"T_1ad14_foot0_row0_col5\" class=\"foot0_data foot0_row0 col5\" >0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ad14_level0_foot0_row1\" class=\"foot0_row_heading level0 foot0_row1\" >std</th>\n",
       "      <td id=\"T_1ad14_foot0_row1_col0\" class=\"foot0_data foot0_row1 col0\" >0.013</td>\n",
       "      <td id=\"T_1ad14_foot0_row1_col1\" class=\"foot0_data foot0_row1 col1\" >0.014</td>\n",
       "      <td id=\"T_1ad14_foot0_row1_col2\" class=\"foot0_data foot0_row1 col2\" >0.012</td>\n",
       "      <td id=\"T_1ad14_foot0_row1_col3\" class=\"foot0_data foot0_row1 col3\" >0.013</td>\n",
       "      <td id=\"T_1ad14_foot0_row1_col4\" class=\"foot0_data foot0_row1 col4\" >0.014</td>\n",
       "      <td id=\"T_1ad14_foot0_row1_col5\" class=\"foot0_data foot0_row1 col5\" >0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1ad14_level0_foot0_row2\" class=\"foot0_row_heading level0 foot0_row2\" >score</th>\n",
       "      <td id=\"T_1ad14_foot0_row2_col0\" class=\"foot0_data foot0_row2 col0\" >0.655</td>\n",
       "      <td id=\"T_1ad14_foot0_row2_col1\" class=\"foot0_data foot0_row2 col1\" >0.657</td>\n",
       "      <td id=\"T_1ad14_foot0_row2_col2\" class=\"foot0_data foot0_row2 col2\" >0.658</td>\n",
       "      <td id=\"T_1ad14_foot0_row2_col3\" class=\"foot0_data foot0_row2 col3\" >0.657</td>\n",
       "      <td id=\"T_1ad14_foot0_row2_col4\" class=\"foot0_data foot0_row2 col4\" >0.656</td>\n",
       "      <td id=\"T_1ad14_foot0_row2_col5\" class=\"foot0_data foot0_row2 col5\" >0.657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x35d511550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_overall(pd.DataFrame(balanced_metric_dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on imbalanced test subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on imbalanced test set...\n",
      "\u001b[32m\u001b[1m# c-index=0.5790, mean=0.6383 std=0.0593\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 0: {'American Indian or Alaska Native': 0.6859756097560976, 'Asian': 0.6604332953249715, 'Black or African-American': 0.6329712554496416, 'More than one race': 0.5106215578284815, 'Native Hawaiian or other Pacific Islander': 0.6661698956780924, 'White': 0.673406935096627}\n",
      "\u001b[32m\u001b[1m# c-index=0.5866, mean=0.6408 std=0.0542\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 1: {'American Indian or Alaska Native': 0.6880081300813008, 'Asian': 0.6563283922462941, 'Black or African-American': 0.6280573413138255, 'More than one race': 0.5271439811172305, 'Native Hawaiian or other Pacific Islander': 0.669150521609538, 'White': 0.6762309599716614}\n",
      "\u001b[32m\u001b[1m# c-index=0.5803, mean=0.6427 std=0.0624\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 2: {'American Indian or Alaska Native': 0.6869918699186992, 'Asian': 0.6581527936145952, 'Black or African-American': 0.6390674647158797, 'More than one race': 0.5082612116443745, 'Native Hawaiian or other Pacific Islander': 0.6855439642324889, 'White': 0.6780021253985122}\n",
      "\u001b[32m\u001b[1m# c-index=0.5713, mean=0.6361 std=0.0648\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 3: {'American Indian or Alaska Native': 0.6808943089430894, 'Asian': 0.6581527936145952, 'Black or African-American': 0.633045148895293, 'More than one race': 0.4956726986624705, 'Native Hawaiian or other Pacific Islander': 0.6713859910581222, 'White': 0.6772444601881371}\n",
      "\u001b[32m\u001b[1m# c-index=0.5877, mean=0.6427 std=0.0550\u001b[0m\n",
      "imbalanced test set evaluation metric for fold 4: {'American Indian or Alaska Native': 0.6910569105691057, 'Asian': 0.6513112884834663, 'Black or African-American': 0.6364442473952561, 'More than one race': 0.5263571990558615, 'Native Hawaiian or other Pacific Islander': 0.6773472429210134, 'White': 0.6738300468374857}\n",
      "\n",
      "ENSEMBLE:\n",
      "\u001b[32m\u001b[1m# c-index=0.5782, mean=0.6393 std=0.0610\u001b[0m\n",
      "imbalanced test set evaluation metric: {'American Indian or Alaska Native': 0.6910569105691057, 'Asian': 0.6513112884834663, 'Black or African-American': 0.6364442473952561, 'More than one race': 0.5263571990558615, 'Native Hawaiian or other Pacific Islander': 0.6773472429210134, 'White': 0.6738300468374857}\n"
     ]
    }
   ],
   "source": [
    "ensemble_imbalanced_metric_dict, imbalanced_metric_dicts = evaluate_test_set(test, \"xgb_model_custom_loss\", \n",
    "                                                                             skf, FEATURES, custom_score, dataset_name=\"imbalanced test set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_02bfa_row0_col0 {\n",
       "  background-color: #f906ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row0_col1 {\n",
       "  background-color: #fc03ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row0_col2, #T_02bfa_row0_col5 {\n",
       "  background-color: #fa05ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row0_col3 {\n",
       "  background-color: #f20dff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row0_col4 {\n",
       "  background-color: #ff00ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row1_col0 {\n",
       "  background-color: #d728ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row1_col1 {\n",
       "  background-color: #d22dff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row1_col2, #T_02bfa_row1_col3 {\n",
       "  background-color: #d42bff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row1_col4 {\n",
       "  background-color: #cb34ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row1_col5 {\n",
       "  background-color: #d32cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row2_col0, #T_02bfa_row2_col3 {\n",
       "  background-color: #b34cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row2_col1 {\n",
       "  background-color: #ad52ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row2_col2 {\n",
       "  background-color: #bb44ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row2_col4 {\n",
       "  background-color: #b847ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row2_col5 {\n",
       "  background-color: #b54aff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row3_col0 {\n",
       "  background-color: #13ecff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_02bfa_row3_col1 {\n",
       "  background-color: #29d6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_02bfa_row3_col2 {\n",
       "  background-color: #10efff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_02bfa_row3_col3 {\n",
       "  background-color: #00ffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_02bfa_row3_col4 {\n",
       "  background-color: #28d7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_02bfa_row3_col5 {\n",
       "  background-color: #17e8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_02bfa_row4_col0 {\n",
       "  background-color: #df20ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row4_col1 {\n",
       "  background-color: #e31cff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row4_col2 {\n",
       "  background-color: #f807ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row4_col3 {\n",
       "  background-color: #e619ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row4_col4, #T_02bfa_row5_col2 {\n",
       "  background-color: #ee11ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row4_col5, #T_02bfa_row5_col4 {\n",
       "  background-color: #e916ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row5_col0 {\n",
       "  background-color: #e817ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row5_col1 {\n",
       "  background-color: #ec13ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row5_col3 {\n",
       "  background-color: #ed12ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_02bfa_row5_col5 {\n",
       "  background-color: #eb14ff;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_02bfa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_02bfa_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_02bfa_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_02bfa_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_02bfa_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_02bfa_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_02bfa_level0_col5\" class=\"col_heading level0 col5\" >Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_02bfa_level0_row0\" class=\"row_heading level0 row0\" >American Indian or Alaska Native</th>\n",
       "      <td id=\"T_02bfa_row0_col0\" class=\"data row0 col0\" >0.6860</td>\n",
       "      <td id=\"T_02bfa_row0_col1\" class=\"data row0 col1\" >0.6880</td>\n",
       "      <td id=\"T_02bfa_row0_col2\" class=\"data row0 col2\" >0.6870</td>\n",
       "      <td id=\"T_02bfa_row0_col3\" class=\"data row0 col3\" >0.6809</td>\n",
       "      <td id=\"T_02bfa_row0_col4\" class=\"data row0 col4\" >0.6911</td>\n",
       "      <td id=\"T_02bfa_row0_col5\" class=\"data row0 col5\" >0.6866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02bfa_level0_row1\" class=\"row_heading level0 row1\" >Asian</th>\n",
       "      <td id=\"T_02bfa_row1_col0\" class=\"data row1 col0\" >0.6604</td>\n",
       "      <td id=\"T_02bfa_row1_col1\" class=\"data row1 col1\" >0.6563</td>\n",
       "      <td id=\"T_02bfa_row1_col2\" class=\"data row1 col2\" >0.6582</td>\n",
       "      <td id=\"T_02bfa_row1_col3\" class=\"data row1 col3\" >0.6582</td>\n",
       "      <td id=\"T_02bfa_row1_col4\" class=\"data row1 col4\" >0.6513</td>\n",
       "      <td id=\"T_02bfa_row1_col5\" class=\"data row1 col5\" >0.6569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02bfa_level0_row2\" class=\"row_heading level0 row2\" >Black or African-American</th>\n",
       "      <td id=\"T_02bfa_row2_col0\" class=\"data row2 col0\" >0.6330</td>\n",
       "      <td id=\"T_02bfa_row2_col1\" class=\"data row2 col1\" >0.6281</td>\n",
       "      <td id=\"T_02bfa_row2_col2\" class=\"data row2 col2\" >0.6391</td>\n",
       "      <td id=\"T_02bfa_row2_col3\" class=\"data row2 col3\" >0.6330</td>\n",
       "      <td id=\"T_02bfa_row2_col4\" class=\"data row2 col4\" >0.6364</td>\n",
       "      <td id=\"T_02bfa_row2_col5\" class=\"data row2 col5\" >0.6339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02bfa_level0_row3\" class=\"row_heading level0 row3\" >More than one race</th>\n",
       "      <td id=\"T_02bfa_row3_col0\" class=\"data row3 col0\" >0.5106</td>\n",
       "      <td id=\"T_02bfa_row3_col1\" class=\"data row3 col1\" >0.5271</td>\n",
       "      <td id=\"T_02bfa_row3_col2\" class=\"data row3 col2\" >0.5083</td>\n",
       "      <td id=\"T_02bfa_row3_col3\" class=\"data row3 col3\" >0.4957</td>\n",
       "      <td id=\"T_02bfa_row3_col4\" class=\"data row3 col4\" >0.5264</td>\n",
       "      <td id=\"T_02bfa_row3_col5\" class=\"data row3 col5\" >0.5136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02bfa_level0_row4\" class=\"row_heading level0 row4\" >Native Hawaiian or other Pacific Islander</th>\n",
       "      <td id=\"T_02bfa_row4_col0\" class=\"data row4 col0\" >0.6662</td>\n",
       "      <td id=\"T_02bfa_row4_col1\" class=\"data row4 col1\" >0.6692</td>\n",
       "      <td id=\"T_02bfa_row4_col2\" class=\"data row4 col2\" >0.6855</td>\n",
       "      <td id=\"T_02bfa_row4_col3\" class=\"data row4 col3\" >0.6714</td>\n",
       "      <td id=\"T_02bfa_row4_col4\" class=\"data row4 col4\" >0.6773</td>\n",
       "      <td id=\"T_02bfa_row4_col5\" class=\"data row4 col5\" >0.6739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02bfa_level0_row5\" class=\"row_heading level0 row5\" >White</th>\n",
       "      <td id=\"T_02bfa_row5_col0\" class=\"data row5 col0\" >0.6734</td>\n",
       "      <td id=\"T_02bfa_row5_col1\" class=\"data row5 col1\" >0.6762</td>\n",
       "      <td id=\"T_02bfa_row5_col2\" class=\"data row5 col2\" >0.6780</td>\n",
       "      <td id=\"T_02bfa_row5_col3\" class=\"data row5 col3\" >0.6772</td>\n",
       "      <td id=\"T_02bfa_row5_col4\" class=\"data row5 col4\" >0.6738</td>\n",
       "      <td id=\"T_02bfa_row5_col5\" class=\"data row5 col5\" >0.6757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02bfa_level0_foot0_row0\" class=\"foot0_row_heading level0 foot0_row0\" >mean</th>\n",
       "      <td id=\"T_02bfa_foot0_row0_col0\" class=\"foot0_data foot0_row0 col0\" >0.638</td>\n",
       "      <td id=\"T_02bfa_foot0_row0_col1\" class=\"foot0_data foot0_row0 col1\" >0.641</td>\n",
       "      <td id=\"T_02bfa_foot0_row0_col2\" class=\"foot0_data foot0_row0 col2\" >0.643</td>\n",
       "      <td id=\"T_02bfa_foot0_row0_col3\" class=\"foot0_data foot0_row0 col3\" >0.636</td>\n",
       "      <td id=\"T_02bfa_foot0_row0_col4\" class=\"foot0_data foot0_row0 col4\" >0.643</td>\n",
       "      <td id=\"T_02bfa_foot0_row0_col5\" class=\"foot0_data foot0_row0 col5\" >0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02bfa_level0_foot0_row1\" class=\"foot0_row_heading level0 foot0_row1\" >std</th>\n",
       "      <td id=\"T_02bfa_foot0_row1_col0\" class=\"foot0_data foot0_row1 col0\" >0.059</td>\n",
       "      <td id=\"T_02bfa_foot0_row1_col1\" class=\"foot0_data foot0_row1 col1\" >0.054</td>\n",
       "      <td id=\"T_02bfa_foot0_row1_col2\" class=\"foot0_data foot0_row1 col2\" >0.062</td>\n",
       "      <td id=\"T_02bfa_foot0_row1_col3\" class=\"foot0_data foot0_row1 col3\" >0.065</td>\n",
       "      <td id=\"T_02bfa_foot0_row1_col4\" class=\"foot0_data foot0_row1 col4\" >0.055</td>\n",
       "      <td id=\"T_02bfa_foot0_row1_col5\" class=\"foot0_data foot0_row1 col5\" >0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02bfa_level0_foot0_row2\" class=\"foot0_row_heading level0 foot0_row2\" >score</th>\n",
       "      <td id=\"T_02bfa_foot0_row2_col0\" class=\"foot0_data foot0_row2 col0\" >0.579</td>\n",
       "      <td id=\"T_02bfa_foot0_row2_col1\" class=\"foot0_data foot0_row2 col1\" >0.587</td>\n",
       "      <td id=\"T_02bfa_foot0_row2_col2\" class=\"foot0_data foot0_row2 col2\" >0.580</td>\n",
       "      <td id=\"T_02bfa_foot0_row2_col3\" class=\"foot0_data foot0_row2 col3\" >0.571</td>\n",
       "      <td id=\"T_02bfa_foot0_row2_col4\" class=\"foot0_data foot0_row2 col4\" >0.588</td>\n",
       "      <td id=\"T_02bfa_foot0_row2_col5\" class=\"foot0_data foot0_row2 col5\" >0.581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x35d44dc70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_overall(pd.DataFrame(imbalanced_metric_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race_group\n",
       "White                                        0.456954\n",
       "Black or African-American                    0.245033\n",
       "Asian                                        0.108798\n",
       "American Indian or Alaska Native             0.081362\n",
       "More than one race                           0.053926\n",
       "Native Hawaiian or other Pacific Islander    0.053926\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['race_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:53:37.820277Z",
     "iopub.status.busy": "2024-12-10T06:53:37.819499Z",
     "iopub.status.idle": "2024-12-10T06:53:37.824829Z",
     "shell.execute_reply": "2024-12-10T06:53:37.823859Z",
     "shell.execute_reply.started": "2024-12-10T06:53:37.820232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For inference:\n",
    "# model_path = f\"./xxx/xgb_model.bin\"\n",
    "# model = XGBRegressor()\n",
    "# model.load_model(model_path)\n",
    "# prediction = model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T06:55:23.498382Z",
     "iopub.status.busy": "2024-12-10T06:55:23.497743Z",
     "iopub.status.idle": "2024-12-10T07:01:01.257051Z",
     "shell.execute_reply": "2024-12-10T07:01:01.256322Z",
     "shell.execute_reply.started": "2024-12-10T06:55:23.49835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "    \n",
    "oof_lgb = train[['kfold','ID','efs','efs_time','label','race_group']].copy()\n",
    "oof_lgb['prediction'] = 0.0\n",
    "feature_importances_lgb = pd.DataFrame()\n",
    "feature_importances_lgb['feature'] = FEATURES\n",
    "metric_df = []\n",
    "\n",
    "for fold in range(skf.n_splits):\n",
    "    \n",
    "    x_train = train[train.kfold != fold].copy()\n",
    "    x_valid = train[train.kfold == fold].copy()\n",
    "\n",
    "    y_train = x_train['label']\n",
    "    y_valid = x_valid['label']\n",
    "    y_label = x_valid['efs']\n",
    "\n",
    "    x_train = x_train[FEATURES]\n",
    "    x_valid = x_valid[FEATURES]\n",
    "\n",
    "    ds_true = oof_lgb.loc[oof_lgb.kfold==fold, [\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy().reset_index(drop=True)\n",
    "    ds_pred = oof_lgb.loc[oof_lgb.kfold==fold, [\"ID\"]].copy().reset_index(drop=True)\n",
    "\n",
    "    lgb_params = {\n",
    "        'max_depth': 6,\n",
    "        'num_leaves': 40,\n",
    "        'learning_rate': 0.03,\n",
    "        'n_estimators': 10000,\n",
    "        'objective': 'l2',\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1,\n",
    "        'device': 'gpu',\n",
    "        'metric': 'None' # only show the custom metric\n",
    "    }\n",
    "    clf = LGBMRegressor(**lgb_params)\n",
    "    clf.fit(\n",
    "        x_train, y_train,\n",
    "        eval_set=[(x_valid, y_valid)],\n",
    "        categorical_feature=CAT_FEATURES,\n",
    "        eval_metric=CIndexMetric_LGB, # the custom metric\n",
    "        callbacks=[callback.log_evaluation(500), callback.early_stopping(100)]\n",
    "    )\n",
    "    feature_importances_lgb[f'fold_{fold + 1}'] = clf.feature_importances_\n",
    "\n",
    "    preds_valid = clf.predict(x_valid)\n",
    "    oof_lgb.loc[oof_lgb.kfold==fold, 'prediction'] = preds_valid\n",
    "\n",
    "    joblib.dump(clf, f\"lgb_model_{fold}.pkl\")\n",
    "\n",
    "    y_true = oof_lgb.loc[oof_lgb.kfold==fold, [\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy().reset_index(drop=True)\n",
    "    y_pred = oof_lgb.loc[oof_lgb.kfold==fold, [\"ID\",\"prediction\"]].copy().reset_index(drop=True)\n",
    "    m, metric_dict = custom_score(y_true, y_pred, \"ID\", print_info=True)\n",
    "    metric_df.append(metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T07:01:05.457732Z",
     "iopub.status.busy": "2024-12-10T07:01:05.457276Z",
     "iopub.status.idle": "2024-12-10T07:01:05.462006Z",
     "shell.execute_reply": "2024-12-10T07:01:05.461136Z",
     "shell.execute_reply.started": "2024-12-10T07:01:05.457681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For inference:\n",
    "# model_path = f\"./xxx/lgb_model.pkl\"\n",
    "# model = joblib.load(model_path)\n",
    "# prediction = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T07:01:07.800526Z",
     "iopub.status.busy": "2024-12-10T07:01:07.799836Z",
     "iopub.status.idle": "2024-12-10T07:01:08.123931Z",
     "shell.execute_reply": "2024-12-10T07:01:08.123106Z",
     "shell.execute_reply.started": "2024-12-10T07:01:07.800488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_true = oof_lgb[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy().reset_index(drop=True)\n",
    "y_pred = oof_lgb[[\"ID\",\"prediction\"]].copy().reset_index(drop=True)\n",
    "m, _ = custom_score(y_true, y_pred, \"ID\", print_info=True)\n",
    "print(f\"Overall official SCORE: {m:.5f}\")\n",
    "\n",
    "metric_df_ = pd.DataFrame(metric_df)\n",
    "display_overall(metric_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T07:01:19.336717Z",
     "iopub.status.busy": "2024-12-10T07:01:19.336365Z",
     "iopub.status.idle": "2024-12-10T07:01:19.65227Z",
     "shell.execute_reply": "2024-12-10T07:01:19.651589Z",
     "shell.execute_reply.started": "2024-12-10T07:01:19.336687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "y_pred = train[[\"ID\"]].copy()\n",
    "y_pred[\"prediction\"] = 0.5*oof_xgb['prediction'].rank(pct=True) + 0.5*oof_lgb['prediction'].rank(pct=True)\n",
    "\n",
    "m, _ = custom_score(y_true, y_pred, \"ID\", print_info=True)\n",
    "print(f\"Overall official SCORE: {m:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "sourceId": 70942,
     "sourceType": "competition"
    },
    {
     "sourceId": 211253469,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 211322530,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 212249161,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
